{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Reviewer-oriented package (FULL VERSION + PLOT DATA EXPORT):\n",
    "#  1) KM by Stage Bin (ALL internal + optional external)\n",
    "#  2) KM by Imaging Risk (ALL internal + optional external, external uses INTERNAL cutoff)\n",
    "#  3) KM 4-group: Stage Bin × Imaging Risk (ALL internal + optional external)\n",
    "#  4) Cox UV/MV (ALL internal): Age, pathology, stage_bin, imaging_risk\n",
    "#\n",
    "# PLUS:\n",
    "#  - Save plotting-ready CSVs so you can redraw/modify figures easily.\n",
    "#\n",
    "# Representative model: file04/run06\n",
    "# stage0 coding: 1,2,3,4  -> stage_bin: (1-2) vs (3-4)\n",
    "#\n",
    "# UPDATE (2026-02-17):\n",
    "#  - Cox imaging_risk scaling changed to HR per 0.1 increase (default),\n",
    "#    instead of \"per 1-SD\".\n",
    "#\n",
    "# UPDATE (2026-02-18):\n",
    "#  - Export FULL roster (all columns) with imaging_risk, risk_group, cutoff\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "BASE_GROUP = \"beit0\"\n",
    "GROUP = \"n7_30_30\"\n",
    "\n",
    "REP_FILE_IDX = 4\n",
    "REP_RUN_IDX  = 6\n",
    "\n",
    "# imaging risk is computed from this representative feature set's model\n",
    "REP_FEATURE_FOR_IMAGING = \"Image only\"\n",
    "\n",
    "T0 = 60  # months horizon for risk = 1 - S(T0)\n",
    "\n",
    "# ✅ NEW: Cox imaging_risk unit (HR per this increase in original risk scale)\n",
    "RISK_UNIT_FOR_COX = 0.1\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BASE_SEED = 20250903\n",
    "\n",
    "MODEL_DIR_ROOT = f\"./survival_model/mixture_non_fix/models/{BASE_GROUP}/{GROUP}\"\n",
    "MODEL_DIR_I    = os.path.join(MODEL_DIR_ROOT, f\"file{REP_FILE_IDX:02d}\")\n",
    "\n",
    "DATA_CSV_PATH     = f\"./deephit/{BASE_GROUP}/test/dl0/{GROUP}/dh11_run{REP_FILE_IDX:02d}.csv\"\n",
    "EXTERNAL_CSV_PATH = f\"./external/external{REP_FILE_IDX}.csv\"\n",
    "\n",
    "SAVE_ROOT_BASE = f\"./survival_model/mixture_non_fix/non_nest/{BASE_GROUP}/results/reviewer_km_pack/dl0/{GROUP}\"\n",
    "SAVE_ROOT_I    = os.path.join(SAVE_ROOT_BASE, f\"file{REP_FILE_IDX:02d}_run{REP_RUN_IDX:02d}\")\n",
    "os.makedirs(SAVE_ROOT_I, exist_ok=True)\n",
    "\n",
    "# feature columns (as you used)\n",
    "IMG_COLS  = [\"feat_436\", \"feat_519\"]\n",
    "CONT_COLS = [\"Age\"]\n",
    "CAT_COLS  = [\"pathology\", \"stage0\"]\n",
    "\n",
    "# -------------------------\n",
    "# Utils\n",
    "# -------------------------\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def ensure_time_event(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if \"event\" not in df.columns and \"survival\" in df.columns:\n",
    "        df[\"event\"] = df[\"survival\"].astype(int)\n",
    "    if \"time\" not in df.columns and \"fu_date\" in df.columns:\n",
    "        df[\"time\"] = df[\"fu_date\"].astype(np.float32)\n",
    "\n",
    "    df[\"time\"]  = pd.to_numeric(df[\"time\"], errors=\"coerce\")\n",
    "    df[\"event\"] = pd.to_numeric(df[\"event\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_stage_bin_12_vs_34(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    stage0 coding: 1,2,3,4\n",
    "    stage_bin:\n",
    "      0 => stage0 in {1,2}  (IB–IIIC1)\n",
    "      1 => stage0 in {3,4}  (IIIC2–IVB)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"stage0\"] = pd.to_numeric(df[\"stage0\"], errors=\"coerce\")\n",
    "    df[\"stage_bin\"] = np.where(df[\"stage0\"].isin([1,2]), 0,\n",
    "                        np.where(df[\"stage0\"].isin([3,4]), 1, np.nan))\n",
    "    df[\"stage_bin_label\"] = df[\"stage_bin\"].map({\n",
    "        0: \"IB–IIIC1 (stage0 1–2)\",\n",
    "        1: \"IIIC2–IVB (stage0 3–4)\"\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# PLOT DATA EXPORT helpers\n",
    "# -------------------------\n",
    "def save_km_long_data(df, time_col, event_col, group_col, out_csv):\n",
    "    \"\"\"\n",
    "    Save raw long data for KM re-plotting.\n",
    "    columns: time, event, group\n",
    "    \"\"\"\n",
    "    d = df[[time_col, event_col, group_col]].copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    d = d.rename(columns={time_col: \"time\", event_col: \"event\", group_col: \"group\"})\n",
    "    d.to_csv(out_csv, index=False)\n",
    "    print(f\"✅ KM raw(long) saved: {out_csv}\")\n",
    "\n",
    "def save_risk_long_data(df_time_event_risk, out_csv):\n",
    "    \"\"\"\n",
    "    Save raw data for risk-based KM re-plotting.\n",
    "    columns: time, event, risk\n",
    "    \"\"\"\n",
    "    d = df_time_event_risk.copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"time\",\"event\",\"risk\"])\n",
    "    d[[\"time\",\"event\",\"risk\"]].to_csv(out_csv, index=False)\n",
    "    print(f\"✅ Risk raw saved: {out_csv}\")\n",
    "\n",
    "def save_design_matrix_for_cox(df_design, out_csv):\n",
    "    \"\"\"\n",
    "    Save Cox design matrix as-is (including one-hot columns).\n",
    "    \"\"\"\n",
    "    d = df_design.copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    d.to_csv(out_csv, index=False)\n",
    "    print(f\"✅ Cox design matrix saved: {out_csv}\")\n",
    "\n",
    "# -------------------------\n",
    "# Model + load/predict\n",
    "# -------------------------\n",
    "class MixtureStretchedExponentialSurvival(nn.Module):\n",
    "    def __init__(self, input_dim, num_components=2):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.ReLU()\n",
    "        )\n",
    "        self.pi_layer = nn.Linear(64, num_components)\n",
    "        self.lam_layer = nn.Linear(64, num_components)\n",
    "        self.alpha_layer = nn.Linear(64, num_components)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        pi = F.softmax(self.pi_layer(h), dim=1)\n",
    "        lam = F.softplus(self.lam_layer(h)) + 1e-3\n",
    "        a   = F.softplus(self.alpha_layer(h)) + 1e-3\n",
    "        return pi, lam, a\n",
    "\n",
    "def load_model_and_ct(model_dir, run_idx, label, device=DEVICE, num_components=2):\n",
    "    tag = f\"run{run_idx:02d}_{label.replace(' ', '_')}\"\n",
    "    ckpt_path = os.path.join(model_dir, f\"best_model_{tag}.pt\")\n",
    "    ct_path   = os.path.join(model_dir, f\"ct_{tag}.joblib\")\n",
    "\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Missing model: {ckpt_path}\")\n",
    "    if not os.path.exists(ct_path):\n",
    "        raise FileNotFoundError(f\"Missing ct: {ct_path}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    input_dim = int(ckpt[\"input_dim\"])\n",
    "\n",
    "    model = MixtureStretchedExponentialSurvival(input_dim=input_dim, num_components=num_components).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    ct = joblib.load(ct_path)\n",
    "    return model, ct\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_survival(model, x, times):\n",
    "    model.eval()\n",
    "    pi, lam, a = model(x)\n",
    "    surv = []\n",
    "    for t in times:\n",
    "        t_tensor = torch.tensor([t], dtype=torch.float32, device=x.device)\n",
    "        t_a = torch.pow(t_tensor + 1e-8, a)\n",
    "        S_k = torch.exp(-lam * t_a)\n",
    "        S   = torch.sum(pi * S_k, dim=1)\n",
    "        surv.append(S.detach().cpu().numpy())\n",
    "    return np.vstack(surv)\n",
    "\n",
    "# -------------------------\n",
    "# KM plotting helpers\n",
    "# -------------------------\n",
    "def km_plot_two_groups(df, time_col, event_col, group_col, group_order, title, out_png, out_summary_csv):\n",
    "    d = df[[time_col, event_col, group_col]].copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    d = d[d[group_col].isin(group_order)].copy()\n",
    "    if d[group_col].nunique() < 2:\n",
    "        print(f\"⚠️ Need >=2 groups for KM: {out_png}\")\n",
    "        return\n",
    "\n",
    "    summ = (d.groupby(group_col)\n",
    "              .agg(n=(group_col,\"size\"), events=(event_col,\"sum\"))\n",
    "              .reindex(group_order)\n",
    "              .reset_index())\n",
    "    summ.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for g in group_order:\n",
    "        sub = d[d[group_col] == g]\n",
    "        kmf.fit(sub[time_col], event_observed=sub[event_col], label=f\"{g} (n={len(sub)})\")\n",
    "        kmf.plot(ci_show=True)\n",
    "\n",
    "    a = d[d[group_col] == group_order[0]]\n",
    "    b = d[d[group_col] == group_order[1]]\n",
    "    lr = logrank_test(a[time_col], b[time_col], event_observed_A=a[event_col], event_observed_B=b[event_col])\n",
    "    pval = lr.p_value\n",
    "\n",
    "    plt.title(f\"{title}\\nlog-rank p={pval:.3g}\")\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"✅ KM saved: {out_png}\")\n",
    "\n",
    "def km_plot_by_risk(df_time_event_risk, title, out_png, out_summary_csv, fixed_cut=None):\n",
    "    df = df_time_event_risk.copy()\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"time\",\"event\",\"risk\"])\n",
    "    if len(df) < 10:\n",
    "        print(f\"⚠️ Too few samples for KM risk: {out_png}\")\n",
    "        return None\n",
    "\n",
    "    cut = float(fixed_cut) if fixed_cut is not None else float(np.nanmedian(df[\"risk\"].values))\n",
    "    df[\"risk_group\"] = np.where(df[\"risk\"] >= cut, \"High\", \"Low\")\n",
    "\n",
    "    summ = (df.groupby(\"risk_group\")\n",
    "              .agg(n=(\"risk_group\",\"size\"), events=(\"event\",\"sum\"), median_risk=(\"risk\",\"median\"))\n",
    "              .reset_index())\n",
    "    summ[\"cut_used\"] = cut\n",
    "    summ.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for g in [\"Low\",\"High\"]:\n",
    "        sub = df[df[\"risk_group\"] == g]\n",
    "        kmf.fit(sub[\"time\"], event_observed=sub[\"event\"], label=f\"{g} (n={len(sub)})\")\n",
    "        kmf.plot(ci_show=True)\n",
    "\n",
    "    low  = df[df[\"risk_group\"]==\"Low\"]\n",
    "    high = df[df[\"risk_group\"]==\"High\"]\n",
    "    lr = logrank_test(low[\"time\"], high[\"time\"], event_observed_A=low[\"event\"], event_observed_B=high[\"event\"])\n",
    "    pval = lr.p_value\n",
    "\n",
    "    plt.title(f\"{title}\\ncutoff={cut:.4f} | log-rank p={pval:.3g}\")\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"✅ KM saved: {out_png}\")\n",
    "    return cut\n",
    "\n",
    "def km_plot_four_groups(df, time_col, event_col, group_col, title, out_png, out_summary_csv):\n",
    "    d = df[[time_col,event_col,group_col]].copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if d[group_col].nunique() < 2:\n",
    "        print(f\"⚠️ Need >=2 groups for KM: {out_png}\")\n",
    "        return\n",
    "\n",
    "    summ = (d.groupby(group_col)\n",
    "              .agg(n=(group_col,\"size\"), events=(event_col,\"sum\"))\n",
    "              .reset_index()\n",
    "              .sort_values(group_col))\n",
    "    summ.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for g in sorted(d[group_col].unique()):\n",
    "        sub = d[d[group_col] == g]\n",
    "        kmf.fit(sub[time_col], event_observed=sub[event_col], label=f\"{g} (n={len(sub)})\")\n",
    "        kmf.plot(ci_show=True)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"✅ KM saved: {out_png}\")\n",
    "\n",
    "# -------------------------\n",
    "# Cox helpers (ALL internal)\n",
    "#   ✅ imaging_risk scaled to HR per 0.1 increase\n",
    "# -------------------------\n",
    "def build_design_for_cox(df, use_stage=\"stage_bin\", risk_unit=RISK_UNIT_FOR_COX):\n",
    "    \"\"\"\n",
    "    If risk_unit=0.1:\n",
    "      design uses imaging_risk_perunit = imaging_risk / 0.1\n",
    "      => HR corresponds to +0.1 increase in original imaging_risk.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d[\"Age\"] = pd.to_numeric(d[\"Age\"], errors=\"coerce\")\n",
    "    d[\"imaging_risk\"] = pd.to_numeric(d[\"imaging_risk\"], errors=\"coerce\")\n",
    "\n",
    "    if use_stage == \"stage0\":\n",
    "        d[\"stage0\"] = pd.to_numeric(d[\"stage0\"], errors=\"coerce\")\n",
    "        stage_col = \"stage0\"\n",
    "    else:\n",
    "        d[\"stage_bin\"] = pd.to_numeric(d[\"stage_bin\"], errors=\"coerce\")\n",
    "        stage_col = \"stage_bin\"\n",
    "\n",
    "    ru = float(risk_unit) if risk_unit is not None else 0.1\n",
    "    if ru <= 0:\n",
    "        ru = 0.1\n",
    "    d[\"imaging_risk_perunit\"] = d[\"imaging_risk\"] / ru\n",
    "\n",
    "    pat = d[\"pathology\"].astype(\"category\")\n",
    "    pat_oh = pd.get_dummies(pat, prefix=\"pathology\", drop_first=True)\n",
    "\n",
    "    out = pd.concat(\n",
    "        [d[[\"time\",\"event\",\"Age\",stage_col,\"imaging_risk_perunit\"]].rename(columns={\"imaging_risk_perunit\":\"imaging_risk\"}),\n",
    "         pat_oh],\n",
    "        axis=1\n",
    "    )\n",
    "    out = out.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return out\n",
    "\n",
    "def run_cox_uv_mv(df_design, out_prefix):\n",
    "    time_col, event_col = \"time\",\"event\"\n",
    "    covars = [c for c in df_design.columns if c not in [time_col,event_col]]\n",
    "\n",
    "    # UV\n",
    "    uv_rows = []\n",
    "    for c in covars:\n",
    "        cph = CoxPHFitter()\n",
    "        try:\n",
    "            cph.fit(df_design[[time_col,event_col,c]], duration_col=time_col, event_col=event_col)\n",
    "            s = cph.summary.loc[c]\n",
    "            uv_rows.append({\n",
    "                \"variable\": c,\n",
    "                \"coef\": float(s[\"coef\"]),\n",
    "                \"HR\": float(s[\"exp(coef)\"]),\n",
    "                \"p\": float(s[\"p\"]),\n",
    "                \"HR_95low\": float(s[\"exp(coef) lower 95%\"]),\n",
    "                \"HR_95high\": float(s[\"exp(coef) upper 95%\"]),\n",
    "                \"n\": int(cph._n_examples)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            uv_rows.append({\"variable\": c, \"error\": str(e)})\n",
    "\n",
    "    uv_path = f\"{out_prefix}_UV.csv\"\n",
    "    pd.DataFrame(uv_rows).to_csv(uv_path, index=False)\n",
    "\n",
    "    # MV\n",
    "    mv_path = f\"{out_prefix}_MV.csv\"\n",
    "    cph = CoxPHFitter()\n",
    "    try:\n",
    "        cph.fit(df_design, duration_col=time_col, event_col=event_col)\n",
    "        mv = cph.summary.reset_index().rename(columns={\"index\":\"variable\"})\n",
    "        mv.to_csv(mv_path, index=False)\n",
    "    except Exception as e:\n",
    "        pd.DataFrame([{\"error\": str(e)}]).to_csv(mv_path, index=False)\n",
    "\n",
    "    print(f\"✅ Cox saved: {uv_path} , {mv_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "print(\"============================================\")\n",
    "print(f\"[Reviewer KM Pack] file{REP_FILE_IDX:02d} run{REP_RUN_IDX:02d} | T0={T0}\")\n",
    "print(\"MODEL_DIR_I =\", MODEL_DIR_I)\n",
    "print(\"DATA_CSV    =\", DATA_CSV_PATH)\n",
    "print(\"EXTERNAL    =\", EXTERNAL_CSV_PATH)\n",
    "print(\"OUT_DIR     =\", SAVE_ROOT_I)\n",
    "print(\"============================================\")\n",
    "\n",
    "if not os.path.exists(DATA_CSV_PATH):\n",
    "    raise FileNotFoundError(f\"Missing internal data CSV: {DATA_CSV_PATH}\")\n",
    "\n",
    "df_all = ensure_time_event(pd.read_csv(DATA_CSV_PATH))\n",
    "df_all = add_stage_bin_12_vs_34(df_all)\n",
    "\n",
    "df_ext = None\n",
    "if os.path.exists(EXTERNAL_CSV_PATH):\n",
    "    df_ext = ensure_time_event(pd.read_csv(EXTERNAL_CSV_PATH))\n",
    "    df_ext = add_stage_bin_12_vs_34(df_ext)\n",
    "\n",
    "# -------------------------\n",
    "# 1) KM by Stage Bin (ALL internal)\n",
    "# -------------------------\n",
    "stage_groups = [\"IB–IIIC1 (stage0 1–2)\", \"IIIC2–IVB (stage0 3–4)\"]\n",
    "df_stage_int = df_all[[\"time\",\"event\",\"stage_bin_label\"]].dropna(subset=[\"stage_bin_label\"])\n",
    "\n",
    "save_km_long_data(\n",
    "    df_stage_int, \"time\", \"event\", \"stage_bin_label\",\n",
    "    os.path.join(SAVE_ROOT_I, \"DATA_INTERNAL_ALL_stagebin_long.csv\")\n",
    ")\n",
    "\n",
    "out_png = os.path.join(SAVE_ROOT_I, \"KM_INTERNAL_ALL_stagebin.png\")\n",
    "out_sum = os.path.join(SAVE_ROOT_I, \"KM_INTERNAL_ALL_stagebin_summary.csv\")\n",
    "km_plot_two_groups(\n",
    "    df_stage_int, \"time\",\"event\",\"stage_bin_label\", stage_groups,\n",
    "    title=f\"KM Internal (ALL) by Stage Bin (1–2 vs 3–4) | file{REP_FILE_IDX:02d}\",\n",
    "    out_png=out_png, out_summary_csv=out_sum\n",
    ")\n",
    "\n",
    "if df_ext is not None:\n",
    "    df_stage_ext = df_ext[[\"time\",\"event\",\"stage_bin_label\"]].dropna(subset=[\"stage_bin_label\"])\n",
    "\n",
    "    save_km_long_data(\n",
    "        df_stage_ext, \"time\", \"event\", \"stage_bin_label\",\n",
    "        os.path.join(SAVE_ROOT_I, \"DATA_EXTERNAL_stagebin_long.csv\")\n",
    "    )\n",
    "\n",
    "    out_png = os.path.join(SAVE_ROOT_I, \"KM_EXTERNAL_stagebin.png\")\n",
    "    out_sum = os.path.join(SAVE_ROOT_I, \"KM_EXTERNAL_stagebin_summary.csv\")\n",
    "    km_plot_two_groups(\n",
    "        df_stage_ext, \"time\",\"event\",\"stage_bin_label\", stage_groups,\n",
    "        title=f\"KM External by Stage Bin (1–2 vs 3–4) | external{REP_FILE_IDX:02d}\",\n",
    "        out_png=out_png, out_summary_csv=out_sum\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# 2) KM by Imaging Risk (ALL internal) using representative model\n",
    "# -------------------------\n",
    "model, ct = load_model_and_ct(MODEL_DIR_I, REP_RUN_IDX, REP_FEATURE_FOR_IMAGING, device=DEVICE, num_components=2)\n",
    "\n",
    "used_cols = IMG_COLS + CONT_COLS + CAT_COLS\n",
    "missing_int = [c for c in used_cols if c not in df_all.columns]\n",
    "if missing_int:\n",
    "    raise ValueError(f\"Internal missing required columns for imaging risk: {missing_int}\")\n",
    "\n",
    "# ---- INTERNAL risk\n",
    "X_int_df = df_all[used_cols].copy()\n",
    "X_int = ct.transform(X_int_df)\n",
    "X_int = pd.DataFrame(X_int).fillna(0).values.astype(np.float32)\n",
    "X_int_t = torch.tensor(X_int, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "S_int_T0 = predict_survival(model, X_int_t, [T0])[0, :]\n",
    "risk_int = 1.0 - S_int_T0\n",
    "\n",
    "df_all = df_all.copy()\n",
    "df_all[\"imaging_risk\"] = risk_int\n",
    "\n",
    "# Risk-only plot data\n",
    "df_risk_int = df_all[[\"time\",\"event\",\"imaging_risk\"]].rename(columns={\"imaging_risk\":\"risk\"}).dropna()\n",
    "save_risk_long_data(\n",
    "    df_risk_int,\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_INTERNAL_ALL_imagingRisk_T{T0}.csv\")\n",
    ")\n",
    "\n",
    "out_png = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_imagingRisk_T{T0}.png\")\n",
    "out_sum = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_imagingRisk_T{T0}_summary.csv\")\n",
    "internal_cut = km_plot_by_risk(\n",
    "    df_risk_int,\n",
    "    title=f\"KM Internal (ALL) by Imaging Risk | {REP_FEATURE_FOR_IMAGING}\\nrisk=1-S({T0}) | file{REP_FILE_IDX:02d} run{REP_RUN_IDX:02d}\",\n",
    "    out_png=out_png, out_summary_csv=out_sum, fixed_cut=None\n",
    ")\n",
    "\n",
    "# ✅ NEW: add High/Low group + cutoff into df_all, and export FULL roster\n",
    "df_all[\"imaging_risk_cutoff\"] = internal_cut\n",
    "df_all[\"imaging_risk_group\"] = np.where(df_all[\"imaging_risk\"] >= internal_cut, \"HighRisk\", \"LowRisk\")\n",
    "\n",
    "# ✅ FULL internal roster export (ALL columns)\n",
    "out_full_internal = os.path.join(SAVE_ROOT_I, f\"INTERNAL_ALL_FULL_with_imagingRisk_T{T0}.csv\")\n",
    "df_all.to_csv(out_full_internal, index=False)\n",
    "print(f\"✅ FULL internal roster saved: {out_full_internal}\")\n",
    "\n",
    "# Save risk_group table for easy plotting (High/Low with cutoff)\n",
    "df_risk_int2 = df_risk_int.copy()\n",
    "df_risk_int2[\"cutoff\"] = internal_cut\n",
    "df_risk_int2[\"risk_group\"] = np.where(df_risk_int2[\"risk\"] >= internal_cut, \"High\", \"Low\")\n",
    "df_risk_int2.to_csv(\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_INTERNAL_ALL_imagingRisk_T{T0}_withGroup.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ---- EXTERNAL risk (optional) + FULL roster export\n",
    "if df_ext is not None:\n",
    "    missing_ext = [c for c in used_cols if c not in df_ext.columns]\n",
    "    if missing_ext:\n",
    "        print(\"⚠️ External missing columns for imaging risk KM:\", missing_ext)\n",
    "    else:\n",
    "        X_ext_df = df_ext[used_cols].copy()\n",
    "        X_ext = ct.transform(X_ext_df)\n",
    "        X_ext = pd.DataFrame(X_ext).fillna(0).values.astype(np.float32)\n",
    "        X_ext_t = torch.tensor(X_ext, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "        S_ext_T0 = predict_survival(model, X_ext_t, [T0])[0, :]\n",
    "        risk_ext = 1.0 - S_ext_T0\n",
    "\n",
    "        df_ext = df_ext.copy()\n",
    "        df_ext[\"imaging_risk\"] = risk_ext\n",
    "\n",
    "        df_risk_ext = df_ext[[\"time\",\"event\",\"imaging_risk\"]].rename(columns={\"imaging_risk\":\"risk\"}).dropna()\n",
    "        save_risk_long_data(\n",
    "            df_risk_ext,\n",
    "            os.path.join(SAVE_ROOT_I, f\"DATA_EXTERNAL_imagingRisk_T{T0}.csv\")\n",
    "        )\n",
    "\n",
    "        out_png = os.path.join(SAVE_ROOT_I, f\"KM_EXTERNAL_imagingRisk_T{T0}.png\")\n",
    "        out_sum = os.path.join(SAVE_ROOT_I, f\"KM_EXTERNAL_imagingRisk_T{T0}_summary.csv\")\n",
    "        km_plot_by_risk(\n",
    "            df_risk_ext,\n",
    "            title=f\"KM External by Imaging Risk (INTERNAL cutoff) | risk=1-S({T0})\",\n",
    "            out_png=out_png, out_summary_csv=out_sum, fixed_cut=internal_cut\n",
    "        )\n",
    "\n",
    "        # ✅ NEW: add group + cutoff + export FULL external roster\n",
    "        df_ext[\"imaging_risk_cutoff\"] = internal_cut\n",
    "        df_ext[\"imaging_risk_group\"] = np.where(df_ext[\"imaging_risk\"] >= internal_cut, \"HighRisk\", \"LowRisk\")\n",
    "\n",
    "        out_full_external = os.path.join(SAVE_ROOT_I, f\"EXTERNAL_FULL_with_imagingRisk_T{T0}.csv\")\n",
    "        df_ext.to_csv(out_full_external, index=False)\n",
    "        print(f\"✅ FULL external roster saved: {out_full_external}\")\n",
    "\n",
    "        df_risk_ext2 = df_risk_ext.copy()\n",
    "        df_risk_ext2[\"cutoff\"] = internal_cut\n",
    "        df_risk_ext2[\"risk_group\"] = np.where(df_risk_ext2[\"risk\"] >= internal_cut, \"High\", \"Low\")\n",
    "        df_risk_ext2.to_csv(\n",
    "            os.path.join(SAVE_ROOT_I, f\"DATA_EXTERNAL_imagingRisk_T{T0}_withGroup.csv\"),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "# -------------------------\n",
    "# 3) 4-group KM: Stage Bin × Imaging Risk (ALL internal)\n",
    "# -------------------------\n",
    "df4 = df_all[[\"time\",\"event\",\"stage_bin_label\",\"stage_bin\",\"imaging_risk\"]].dropna(subset=[\"stage_bin\",\"imaging_risk\"]).copy()\n",
    "df4[\"risk_group\"] = np.where(df4[\"imaging_risk\"] >= internal_cut, \"HighRisk\", \"LowRisk\")\n",
    "df4[\"group4\"] = df4[\"stage_bin_label\"] + \" | \" + df4[\"risk_group\"]\n",
    "\n",
    "save_km_long_data(\n",
    "    df4, \"time\", \"event\", \"group4\",\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_INTERNAL_ALL_stagebin_x_imagingRisk_T{T0}_long.csv\")\n",
    ")\n",
    "\n",
    "out_png = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_stagebin_x_imagingRisk_T{T0}.png\")\n",
    "out_sum = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_stagebin_x_imagingRisk_T{T0}_summary.csv\")\n",
    "km_plot_four_groups(\n",
    "    df4, \"time\",\"event\",\"group4\",\n",
    "    title=f\"KM Internal (ALL) | Stage Bin × Imaging Risk\\ncutoff(from internal median risk) | T0={T0}\",\n",
    "    out_png=out_png, out_summary_csv=out_sum\n",
    ")\n",
    "\n",
    "if df_ext is not None and \"imaging_risk\" in df_ext.columns:\n",
    "    df4e = df_ext[[\"time\",\"event\",\"stage_bin_label\",\"stage_bin\",\"imaging_risk\"]].dropna(subset=[\"stage_bin\",\"imaging_risk\"]).copy()\n",
    "    df4e[\"risk_group\"] = np.where(df4e[\"imaging_risk\"] >= internal_cut, \"HighRisk\", \"LowRisk\")\n",
    "    df4e[\"group4\"] = df4e[\"stage_bin_label\"] + \" | \" + df4e[\"risk_group\"]\n",
    "\n",
    "    save_km_long_data(\n",
    "        df4e, \"time\", \"event\", \"group4\",\n",
    "        os.path.join(SAVE_ROOT_I, f\"DATA_EXTERNAL_stagebin_x_imagingRisk_T{T0}_long.csv\")\n",
    "    )\n",
    "\n",
    "    out_png = os.path.join(SAVE_ROOT_I, f\"KM_EXTERNAL_stagebin_x_imagingRisk_T{T0}.png\")\n",
    "    out_sum = os.path.join(SAVE_ROOT_I, f\"KM_EXTERNAL_stagebin_x_imagingRisk_T{T0}_summary.csv\")\n",
    "    km_plot_four_groups(\n",
    "        df4e, \"time\",\"event\",\"group4\",\n",
    "        title=f\"KM External | Stage Bin × Imaging Risk (internal cutoff) | T0={T0}\",\n",
    "        out_png=out_png, out_summary_csv=out_sum\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# 4) Cox UV/MV (ALL internal): Age, pathology, stage_bin, imaging_risk\n",
    "# -------------------------\n",
    "df_cox = df_all[[\"time\",\"event\",\"Age\",\"pathology\",\"stage0\",\"stage_bin\",\"imaging_risk\"]].copy()\n",
    "df_cox = df_cox.dropna(subset=[\"time\",\"event\",\"Age\",\"pathology\",\"stage_bin\",\"imaging_risk\"])\n",
    "\n",
    "# (a) stage_bin model\n",
    "design_bin = build_design_for_cox(df_cox, use_stage=\"stage_bin\", risk_unit=RISK_UNIT_FOR_COX)\n",
    "save_design_matrix_for_cox(\n",
    "    design_bin,\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_CoxDesign_INTERNAL_T{T0}_stageBIN_imgrisk_per0p1.csv\")\n",
    ")\n",
    "out_prefix = os.path.join(SAVE_ROOT_I, f\"Cox_INTERNAL_ALL_T{T0}_stageBIN_imgrisk_per0p1\")\n",
    "run_cox_uv_mv(design_bin, out_prefix)\n",
    "\n",
    "# (b) stage0 ordinal (optional)\n",
    "design_s0 = build_design_for_cox(df_cox, use_stage=\"stage0\", risk_unit=RISK_UNIT_FOR_COX)\n",
    "save_design_matrix_for_cox(\n",
    "    design_s0,\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_CoxDesign_INTERNAL_T{T0}_stage0_imgrisk_per0p1.csv\")\n",
    ")\n",
    "out_prefix = os.path.join(SAVE_ROOT_I, f\"Cox_INTERNAL_ALL_T{T0}_stage0_imgrisk_per0p1\")\n",
    "run_cox_uv_mv(design_s0, out_prefix)\n",
    "\n",
    "print(\"\\n✅ DONE. Output directory:\")\n",
    "print(SAVE_ROOT_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Reviewer-oriented package (FULL VERSION + PLOT DATA EXPORT):\n",
    "#  1) KM by Stage Bin (ALL internal)\n",
    "#  2) KM by Imaging Risk (ALL internal)\n",
    "#  3) KM 4-group: Stage Bin × Imaging Risk (ALL internal)\n",
    "#  4) Cox UV/MV (ALL internal):\n",
    "#       - stage : categorical (SAFE, one-hot)\n",
    "#       - imaging_risk : continuous (HR per 0.1 increase) ✅\n",
    "#\n",
    "# NOTE:\n",
    "#  - This script assumes PFS-like endpoint:\n",
    "#      event <- recur\n",
    "#      time  <- recur_date\n",
    "#\n",
    "# UPDATE (2026-02-17):\n",
    "#  - Cox imaging_risk scaling changed from z-score (per 1-SD)\n",
    "#    to per 0.1 increase by default.\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "BASE_GROUP = \"beit0\"\n",
    "GROUP = \"n7_30_30\"\n",
    "\n",
    "REP_FILE_IDX = 4\n",
    "REP_RUN_IDX  = 6\n",
    "\n",
    "REP_FEATURE_FOR_IMAGING = \"Image only\"\n",
    "T0 = 60  # months horizon for risk = 1 - S(T0)\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BASE_SEED = 20250903\n",
    "\n",
    "MODEL_DIR_ROOT = f\"./survival_model/mixture_non_fix/models/{BASE_GROUP}/{GROUP}\"\n",
    "MODEL_DIR_I    = os.path.join(MODEL_DIR_ROOT, f\"file{REP_FILE_IDX:02d}\")\n",
    "\n",
    "DATA_CSV_PATH     = f\"./deephit/{BASE_GROUP}/test/dl0/{GROUP}/dh11_run{REP_FILE_IDX:02d}.csv\"\n",
    "\n",
    "SAVE_ROOT_BASE = f\"./survival_model/mixture_non_fix/non_nest/{BASE_GROUP}/results/reviewer_km_pack_pfs/dl0/{GROUP}\"\n",
    "SAVE_ROOT_I    = os.path.join(SAVE_ROOT_BASE, f\"file{REP_FILE_IDX:02d}_run{REP_RUN_IDX:02d}\")\n",
    "os.makedirs(SAVE_ROOT_I, exist_ok=True)\n",
    "\n",
    "# feature columns (as you used)\n",
    "IMG_COLS  = [\"feat_436\", \"feat_519\"]\n",
    "CONT_COLS = [\"Age\"]\n",
    "CAT_COLS  = [\"pathology\", \"stage0\"]\n",
    "\n",
    "# -------------------------\n",
    "# Utils\n",
    "# -------------------------\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def ensure_time_event(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PFS-like:\n",
    "      - event <- recur\n",
    "      - time  <- recur_date\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"event\" not in df.columns and \"recur\" in df.columns:\n",
    "        df[\"event\"] = df[\"recur\"].astype(int)\n",
    "\n",
    "    if \"time\" not in df.columns and \"recur_date\" in df.columns:\n",
    "        df[\"time\"] = df[\"recur_date\"].astype(np.float32)\n",
    "\n",
    "    if \"time\" in df.columns:\n",
    "        df[\"time\"] = pd.to_numeric(df[\"time\"], errors=\"coerce\")\n",
    "\n",
    "    if \"event\" in df.columns:\n",
    "        df[\"event\"] = pd.to_numeric(df[\"event\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_stage_bin_12_vs_34(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    stage0 coding: 1,2,3,4\n",
    "    stage_bin:\n",
    "      0 => stage0 in {1,2}  (IB–IIIC1)\n",
    "      1 => stage0 in {3,4}  (IIIC2–IVB)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if \"stage0\" in df.columns:\n",
    "        df[\"stage0\"] = pd.to_numeric(df[\"stage0\"], errors=\"coerce\")\n",
    "        df[\"stage_bin\"] = np.where(df[\"stage0\"].isin([1, 2]), 0,\n",
    "                            np.where(df[\"stage0\"].isin([3, 4]), 1, np.nan))\n",
    "        df[\"stage_bin_label\"] = df[\"stage_bin\"].map({\n",
    "            0: \"IB–IIIC1 (stage0 1–2)\",\n",
    "            1: \"IIIC2–IVB (stage0 3–4)\"\n",
    "        })\n",
    "    else:\n",
    "        df[\"stage_bin\"] = np.nan\n",
    "        df[\"stage_bin_label\"] = np.nan\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# PLOT DATA EXPORT helpers\n",
    "# -------------------------\n",
    "def save_km_long_data(df, time_col, event_col, group_col, out_csv):\n",
    "    d = df[[time_col, event_col, group_col]].copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    d = d.rename(columns={time_col: \"time\", event_col: \"event\", group_col: \"group\"})\n",
    "    d.to_csv(out_csv, index=False)\n",
    "    print(f\"✅ KM raw(long) saved: {out_csv}\")\n",
    "\n",
    "def save_risk_long_data(df_time_event_risk, out_csv):\n",
    "    d = df_time_event_risk.copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"time\",\"event\",\"risk\"])\n",
    "    d[[\"time\",\"event\",\"risk\"]].to_csv(out_csv, index=False)\n",
    "    print(f\"✅ Risk raw saved: {out_csv}\")\n",
    "\n",
    "def save_design_matrix_for_cox(df_design, out_csv):\n",
    "    d = df_design.copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    d.to_csv(out_csv, index=False)\n",
    "    print(f\"✅ Cox design matrix saved: {out_csv}\")\n",
    "\n",
    "# -------------------------\n",
    "# Model + load/predict\n",
    "# -------------------------\n",
    "class MixtureStretchedExponentialSurvival(nn.Module):\n",
    "    def __init__(self, input_dim, num_components=2):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.ReLU()\n",
    "        )\n",
    "        self.pi_layer = nn.Linear(64, num_components)\n",
    "        self.lam_layer = nn.Linear(64, num_components)\n",
    "        self.alpha_layer = nn.Linear(64, num_components)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        pi = F.softmax(self.pi_layer(h), dim=1)\n",
    "        lam = F.softplus(self.lam_layer(h)) + 1e-3\n",
    "        a   = F.softplus(self.alpha_layer(h)) + 1e-3\n",
    "        return pi, lam, a\n",
    "\n",
    "def load_model_and_ct(model_dir, run_idx, label, device=DEVICE, num_components=2):\n",
    "    tag = f\"run{run_idx:02d}_{label.replace(' ', '_')}\"\n",
    "    ckpt_path = os.path.join(model_dir, f\"best_model_{tag}.pt\")\n",
    "    ct_path   = os.path.join(model_dir, f\"ct_{tag}.joblib\")\n",
    "\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Missing model: {ckpt_path}\")\n",
    "    if not os.path.exists(ct_path):\n",
    "        raise FileNotFoundError(f\"Missing ct: {ct_path}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    input_dim = int(ckpt[\"input_dim\"])\n",
    "\n",
    "    model = MixtureStretchedExponentialSurvival(input_dim=input_dim, num_components=num_components).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    ct = joblib.load(ct_path)\n",
    "    return model, ct\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_survival(model, x, times):\n",
    "    model.eval()\n",
    "    pi, lam, a = model(x)\n",
    "    surv = []\n",
    "    for t in times:\n",
    "        t_tensor = torch.tensor([t], dtype=torch.float32, device=x.device)\n",
    "        t_a = torch.pow(t_tensor + 1e-8, a)\n",
    "        S_k = torch.exp(-lam * t_a)\n",
    "        S   = torch.sum(pi * S_k, dim=1)\n",
    "        surv.append(S.detach().cpu().numpy())\n",
    "    return np.vstack(surv)\n",
    "\n",
    "# -------------------------\n",
    "# KM plotting helpers\n",
    "# -------------------------\n",
    "def km_plot_two_groups(df, time_col, event_col, group_col, group_order, title, out_png, out_summary_csv):\n",
    "    d = df[[time_col, event_col, group_col]].copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    d = d[d[group_col].isin(group_order)].copy()\n",
    "    if d[group_col].nunique() < 2:\n",
    "        print(f\"⚠️ Need >=2 groups for KM: {out_png}\")\n",
    "        return\n",
    "\n",
    "    summ = (d.groupby(group_col)\n",
    "              .agg(n=(group_col,\"size\"), events=(event_col,\"sum\"))\n",
    "              .reindex(group_order)\n",
    "              .reset_index())\n",
    "    summ.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for g in group_order:\n",
    "        sub = d[d[group_col] == g]\n",
    "        kmf.fit(sub[time_col], event_observed=sub[event_col], label=f\"{g} (n={len(sub)})\")\n",
    "        kmf.plot(ci_show=True)\n",
    "\n",
    "    a = d[d[group_col] == group_order[0]]\n",
    "    b = d[d[group_col] == group_order[1]]\n",
    "    lr = logrank_test(a[time_col], b[time_col], event_observed_A=a[event_col], event_observed_B=b[event_col])\n",
    "    pval = lr.p_value\n",
    "\n",
    "    plt.title(f\"{title}\\nlog-rank p={pval:.3g}\")\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"✅ KM saved: {out_png}\")\n",
    "\n",
    "def km_plot_by_risk(df_time_event_risk, title, out_png, out_summary_csv, fixed_cut=None):\n",
    "    df = df_time_event_risk.copy()\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"time\",\"event\",\"risk\"])\n",
    "    if len(df) < 10:\n",
    "        print(f\"⚠️ Too few samples for KM risk: {out_png}\")\n",
    "        return None\n",
    "\n",
    "    cut = float(fixed_cut) if fixed_cut is not None else float(np.nanmedian(df[\"risk\"].values))\n",
    "    df[\"risk_group\"] = np.where(df[\"risk\"] >= cut, \"High\", \"Low\")\n",
    "\n",
    "    summ = (df.groupby(\"risk_group\")\n",
    "              .agg(n=(\"risk_group\",\"size\"), events=(\"event\",\"sum\"), median_risk=(\"risk\",\"median\"))\n",
    "              .reset_index())\n",
    "    summ[\"cut_used\"] = cut\n",
    "    summ.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for g in [\"Low\",\"High\"]:\n",
    "        sub = df[df[\"risk_group\"] == g]\n",
    "        kmf.fit(sub[\"time\"], event_observed=sub[\"event\"], label=f\"{g} (n={len(sub)})\")\n",
    "        kmf.plot(ci_show=True)\n",
    "\n",
    "    low  = df[df[\"risk_group\"]==\"Low\"]\n",
    "    high = df[df[\"risk_group\"]==\"High\"]\n",
    "    lr = logrank_test(low[\"time\"], high[\"time\"], event_observed_A=low[\"event\"], event_observed_B=high[\"event\"])\n",
    "    pval = lr.p_value\n",
    "\n",
    "    plt.title(f\"{title}\\ncutoff={cut:.4f} | log-rank p={pval:.3g}\")\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"✅ KM saved: {out_png}\")\n",
    "    return cut\n",
    "\n",
    "def km_plot_four_groups(df, time_col, event_col, group_col, title, out_png, out_summary_csv):\n",
    "    d = df[[time_col,event_col,group_col]].copy()\n",
    "    d = d.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if d[group_col].nunique() < 2:\n",
    "        print(f\"⚠️ Need >=2 groups for KM: {out_png}\")\n",
    "        return\n",
    "\n",
    "    summ = (d.groupby(group_col)\n",
    "              .agg(n=(group_col,\"size\"), events=(event_col,\"sum\"))\n",
    "              .reset_index()\n",
    "              .sort_values(group_col))\n",
    "    summ.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for g in sorted(d[group_col].unique()):\n",
    "        sub = d[d[group_col] == g]\n",
    "        kmf.fit(sub[time_col], event_observed=sub[event_col], label=f\"{g} (n={len(sub)})\")\n",
    "        kmf.plot(ci_show=True)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (Months)\")\n",
    "    plt.ylabel(\"Survival probability\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"✅ KM saved: {out_png}\")\n",
    "\n",
    "# -------------------------\n",
    "# Cox helpers (stage categorical + imaging_risk continuous)\n",
    "#   ✅ imaging_risk scaled to HR per 0.1 increase\n",
    "# -------------------------\n",
    "def build_design_for_cox(\n",
    "    df: pd.DataFrame,\n",
    "    stage_mode: str = \"stage0_cat\",   # \"stage0_cat\" | \"stage_bin_cat\" | \"stage_bin_num\"\n",
    "    risk_unit: float = 0.1,           # ✅ HR per 0.1 increase (default)\n",
    "    standardize_risk: bool = False,   # ✅ z-score OFF by default\n",
    "    standardize_age: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cox design:\n",
    "      - Age: continuous (optional z-score)\n",
    "      - imaging_risk: continuous\n",
    "          * if standardize_risk=True -> HR per 1-SD\n",
    "          * else -> HR per risk_unit (default 0.1) ✅\n",
    "      - pathology: categorical (one-hot, drop_first)\n",
    "      - stage: categorical safe (one-hot) ✅\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "\n",
    "    # numeric casts\n",
    "    d[\"Age\"] = pd.to_numeric(d[\"Age\"], errors=\"coerce\")\n",
    "    d[\"imaging_risk\"] = pd.to_numeric(d[\"imaging_risk\"], errors=\"coerce\")\n",
    "    d[\"time\"] = pd.to_numeric(d[\"time\"], errors=\"coerce\")\n",
    "    d[\"event\"] = pd.to_numeric(d[\"event\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    # required columns by stage mode\n",
    "    req = [\"time\",\"event\",\"Age\",\"imaging_risk\",\"pathology\"]\n",
    "    if stage_mode == \"stage0_cat\":\n",
    "        req += [\"stage0\"]\n",
    "        d[\"stage0\"] = pd.to_numeric(d[\"stage0\"], errors=\"coerce\")\n",
    "    else:\n",
    "        req += [\"stage_bin\"]\n",
    "        d[\"stage_bin\"] = pd.to_numeric(d[\"stage_bin\"], errors=\"coerce\")\n",
    "\n",
    "    d = d[req].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    # imaging_risk continuous scaling\n",
    "    if standardize_risk:\n",
    "        mu = d[\"imaging_risk\"].mean()\n",
    "        sd = d[\"imaging_risk\"].std(ddof=0)\n",
    "        if sd and sd > 0 and not np.isnan(sd):\n",
    "            d[\"imaging_risk_cont\"] = (d[\"imaging_risk\"] - mu) / sd\n",
    "        else:\n",
    "            d[\"imaging_risk_cont\"] = d[\"imaging_risk\"]\n",
    "    else:\n",
    "        # ✅ HR per risk_unit increase\n",
    "        if risk_unit is None or float(risk_unit) <= 0:\n",
    "            risk_unit = 0.1\n",
    "        d[\"imaging_risk_cont\"] = d[\"imaging_risk\"] / float(risk_unit)\n",
    "\n",
    "    # Age scaling optional\n",
    "    if standardize_age:\n",
    "        mu = d[\"Age\"].mean()\n",
    "        sd = d[\"Age\"].std(ddof=0)\n",
    "        if sd and sd > 0 and not np.isnan(sd):\n",
    "            d[\"Age_cont\"] = (d[\"Age\"] - mu) / sd\n",
    "        else:\n",
    "            d[\"Age_cont\"] = d[\"Age\"]\n",
    "    else:\n",
    "        d[\"Age_cont\"] = d[\"Age\"]\n",
    "\n",
    "    # pathology one-hot\n",
    "    pat = d[\"pathology\"].astype(\"category\")\n",
    "    pat_oh = pd.get_dummies(pat, prefix=\"pathology\", drop_first=True)\n",
    "\n",
    "    # stage encoding\n",
    "    if stage_mode == \"stage0_cat\":\n",
    "        st = d[\"stage0\"].astype(\"Int64\").astype(\"category\")\n",
    "        stage_enc = pd.get_dummies(st, prefix=\"stage0\", drop_first=True)\n",
    "    elif stage_mode == \"stage_bin_cat\":\n",
    "        st = d[\"stage_bin\"].astype(\"Int64\").astype(\"category\")\n",
    "        stage_enc = pd.get_dummies(st, prefix=\"stage_bin\", drop_first=True)\n",
    "    elif stage_mode == \"stage_bin_num\":\n",
    "        stage_enc = d[[\"stage_bin\"]].copy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown stage_mode: {stage_mode}\")\n",
    "\n",
    "    core = d[[\"time\",\"event\",\"Age_cont\",\"imaging_risk_cont\"]].copy()\n",
    "    core = core.rename(columns={\"Age_cont\":\"Age\", \"imaging_risk_cont\":\"imaging_risk\"})\n",
    "\n",
    "    out = pd.concat([core, stage_enc, pat_oh], axis=1)\n",
    "    out = out.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return out\n",
    "\n",
    "def run_cox_uv_mv(df_design, out_prefix):\n",
    "    time_col, event_col = \"time\",\"event\"\n",
    "    covars = [c for c in df_design.columns if c not in [time_col,event_col]]\n",
    "\n",
    "    # UV\n",
    "    uv_rows = []\n",
    "    for c in covars:\n",
    "        cph = CoxPHFitter()\n",
    "        try:\n",
    "            cph.fit(df_design[[time_col,event_col,c]], duration_col=time_col, event_col=event_col)\n",
    "            s = cph.summary.loc[c]\n",
    "            uv_rows.append({\n",
    "                \"variable\": c,\n",
    "                \"coef\": float(s[\"coef\"]),\n",
    "                \"HR\": float(s[\"exp(coef)\"]),\n",
    "                \"p\": float(s[\"p\"]),\n",
    "                \"HR_95low\": float(s[\"exp(coef) lower 95%\"]),\n",
    "                \"HR_95high\": float(s[\"exp(coef) upper 95%\"]),\n",
    "                \"n\": int(cph._n_examples)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            uv_rows.append({\"variable\": c, \"error\": str(e)})\n",
    "\n",
    "    uv_path = f\"{out_prefix}_UV.csv\"\n",
    "    pd.DataFrame(uv_rows).to_csv(uv_path, index=False)\n",
    "\n",
    "    # MV\n",
    "    mv_path = f\"{out_prefix}_MV.csv\"\n",
    "    cph = CoxPHFitter()\n",
    "    try:\n",
    "        cph.fit(df_design, duration_col=time_col, event_col=event_col)\n",
    "        mv = cph.summary.reset_index().rename(columns={\"index\":\"variable\"})\n",
    "        mv.to_csv(mv_path, index=False)\n",
    "    except Exception as e:\n",
    "        pd.DataFrame([{\"error\": str(e)}]).to_csv(mv_path, index=False)\n",
    "\n",
    "    print(f\"✅ Cox saved: {uv_path} , {mv_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "set_seed(BASE_SEED)\n",
    "\n",
    "print(\"============================================\")\n",
    "print(f\"[Reviewer KM Pack PFS] file{REP_FILE_IDX:02d} run{REP_RUN_IDX:02d} | T0={T0}\")\n",
    "print(\"MODEL_DIR_I =\", MODEL_DIR_I)\n",
    "print(\"DATA_CSV    =\", DATA_CSV_PATH)\n",
    "print(\"OUT_DIR     =\", SAVE_ROOT_I)\n",
    "print(\"============================================\")\n",
    "\n",
    "if not os.path.exists(DATA_CSV_PATH):\n",
    "    raise FileNotFoundError(f\"Missing internal data CSV: {DATA_CSV_PATH}\")\n",
    "\n",
    "df_all = ensure_time_event(pd.read_csv(DATA_CSV_PATH))\n",
    "df_all = add_stage_bin_12_vs_34(df_all)\n",
    "\n",
    "# -------------------------\n",
    "# 1) KM by Stage Bin (ALL internal)\n",
    "# -------------------------\n",
    "stage_groups = [\"IB–IIIC1 (stage0 1–2)\", \"IIIC2–IVB (stage0 3–4)\"]\n",
    "df_stage_int = df_all[[\"time\",\"event\",\"stage_bin_label\"]].dropna(subset=[\"stage_bin_label\"])\n",
    "\n",
    "save_km_long_data(\n",
    "    df_stage_int, \"time\", \"event\", \"stage_bin_label\",\n",
    "    os.path.join(SAVE_ROOT_I, \"DATA_INTERNAL_ALL_stagebin_long.csv\")\n",
    ")\n",
    "\n",
    "out_png = os.path.join(SAVE_ROOT_I, \"KM_INTERNAL_ALL_stagebin.png\")\n",
    "out_sum = os.path.join(SAVE_ROOT_I, \"KM_INTERNAL_ALL_stagebin_summary.csv\")\n",
    "km_plot_two_groups(\n",
    "    df_stage_int, \"time\",\"event\",\"stage_bin_label\", stage_groups,\n",
    "    title=f\"KM Internal (ALL) by Stage Bin (1–2 vs 3–4) | file{REP_FILE_IDX:02d}\",\n",
    "    out_png=out_png, out_summary_csv=out_sum\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 2) KM by Imaging Risk (ALL internal) using representative model\n",
    "# -------------------------\n",
    "model, ct = load_model_and_ct(MODEL_DIR_I, REP_RUN_IDX, REP_FEATURE_FOR_IMAGING, device=DEVICE, num_components=2)\n",
    "\n",
    "used_cols = IMG_COLS + CONT_COLS + CAT_COLS\n",
    "missing_int = [c for c in used_cols if c not in df_all.columns]\n",
    "if missing_int:\n",
    "    raise ValueError(f\"Internal missing required columns for imaging risk: {missing_int}\")\n",
    "\n",
    "X_int_df = df_all[used_cols].copy()\n",
    "X_int = ct.transform(X_int_df)\n",
    "X_int = pd.DataFrame(X_int).fillna(0).values.astype(np.float32)\n",
    "X_int_t = torch.tensor(X_int, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "S_int_T0 = predict_survival(model, X_int_t, [T0])[0, :]\n",
    "risk_int = 1.0 - S_int_T0\n",
    "\n",
    "df_all = df_all.copy()\n",
    "df_all[\"imaging_risk\"] = risk_int\n",
    "\n",
    "df_all[[\"time\",\"event\",\"stage0\",\"stage_bin\",\"stage_bin_label\",\"Age\",\"pathology\",\"imaging_risk\"]].to_csv(\n",
    "    os.path.join(SAVE_ROOT_I, f\"INTERNAL_ALL_with_imagingRisk_T{T0}.csv\"), index=False\n",
    ")\n",
    "\n",
    "df_risk_int = df_all[[\"time\",\"event\",\"imaging_risk\"]].rename(columns={\"imaging_risk\":\"risk\"}).dropna()\n",
    "save_risk_long_data(\n",
    "    df_risk_int,\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_INTERNAL_ALL_imagingRisk_T{T0}.csv\")\n",
    ")\n",
    "\n",
    "out_png = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_imagingRisk_T{T0}.png\")\n",
    "out_sum = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_imagingRisk_T{T0}_summary.csv\")\n",
    "internal_cut = km_plot_by_risk(\n",
    "    df_risk_int,\n",
    "    title=f\"KM Internal (ALL) by Imaging Risk | {REP_FEATURE_FOR_IMAGING}\\nrisk=1-S({T0}) | file{REP_FILE_IDX:02d} run{REP_RUN_IDX:02d}\",\n",
    "    out_png=out_png, out_summary_csv=out_sum, fixed_cut=None\n",
    ")\n",
    "\n",
    "df_risk_int2 = df_risk_int.copy()\n",
    "df_risk_int2[\"cutoff\"] = internal_cut\n",
    "df_risk_int2[\"risk_group\"] = np.where(df_risk_int2[\"risk\"] >= internal_cut, \"High\", \"Low\")\n",
    "df_risk_int2.to_csv(\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_INTERNAL_ALL_imagingRisk_T{T0}_withGroup.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 3) 4-group KM: Stage Bin × Imaging Risk (ALL internal)\n",
    "# -------------------------\n",
    "df4 = df_all[[\"time\",\"event\",\"stage_bin_label\",\"stage_bin\",\"imaging_risk\"]].dropna(subset=[\"stage_bin\",\"imaging_risk\"]).copy()\n",
    "df4[\"risk_group\"] = np.where(df4[\"imaging_risk\"] >= internal_cut, \"HighRisk\", \"LowRisk\")\n",
    "df4[\"group4\"] = df4[\"stage_bin_label\"] + \" | \" + df4[\"risk_group\"]\n",
    "\n",
    "save_km_long_data(\n",
    "    df4, \"time\", \"event\", \"group4\",\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_INTERNAL_ALL_stagebin_x_imagingRisk_T{T0}_long.csv\")\n",
    ")\n",
    "\n",
    "out_png = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_stagebin_x_imagingRisk_T{T0}.png\")\n",
    "out_sum = os.path.join(SAVE_ROOT_I, f\"KM_INTERNAL_ALL_stagebin_x_imagingRisk_T{T0}_summary.csv\")\n",
    "km_plot_four_groups(\n",
    "    df4, \"time\",\"event\",\"group4\",\n",
    "    title=f\"KM Internal (ALL) | Stage Bin × Imaging Risk\\ncutoff(from internal median risk) | T0={T0}\",\n",
    "    out_png=out_png, out_summary_csv=out_sum\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 4) Cox UV/MV\n",
    "#     - stage categorical safe\n",
    "#     - imaging_risk continuous (HR per 0.1 increase) ✅\n",
    "# -------------------------\n",
    "df_cox = df_all[[\"time\",\"event\",\"Age\",\"pathology\",\"stage0\",\"stage_bin\",\"imaging_risk\"]].copy()\n",
    "df_cox = df_cox.dropna(subset=[\"time\",\"event\",\"Age\",\"pathology\",\"stage0\",\"stage_bin\",\"imaging_risk\"])\n",
    "\n",
    "# (a) Recommended: stage0 categorical (SAFE)\n",
    "design_stage0 = build_design_for_cox(\n",
    "    df_cox,\n",
    "    stage_mode=\"stage0_cat\",\n",
    "    risk_unit=0.1,            # ✅ HR per 0.1 increase\n",
    "    standardize_risk=False,   # ✅ not z-score\n",
    "    standardize_age=False\n",
    ")\n",
    "save_design_matrix_for_cox(\n",
    "    design_stage0,\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_CoxDesign_INTERNAL_T{T0}_stage0CATEG_imgrisk_per0p1.csv\")\n",
    ")\n",
    "out_prefix = os.path.join(SAVE_ROOT_I, f\"Cox_INTERNAL_ALL_T{T0}_stage0CATEG_imgrisk_per0p1\")\n",
    "run_cox_uv_mv(design_stage0, out_prefix)\n",
    "\n",
    "# (b) Optional: stage_bin categorical\n",
    "design_stagebin_cat = build_design_for_cox(\n",
    "    df_cox,\n",
    "    stage_mode=\"stage_bin_cat\",\n",
    "    risk_unit=0.1,\n",
    "    standardize_risk=False,\n",
    "    standardize_age=False\n",
    ")\n",
    "save_design_matrix_for_cox(\n",
    "    design_stagebin_cat,\n",
    "    os.path.join(SAVE_ROOT_I, f\"DATA_CoxDesign_INTERNAL_T{T0}_stageBINCATEG_imgrisk_per0p1.csv\")\n",
    ")\n",
    "out_prefix = os.path.join(SAVE_ROOT_I, f\"Cox_INTERNAL_ALL_T{T0}_stageBINCATEG_imgrisk_per0p1\")\n",
    "run_cox_uv_mv(design_stagebin_cat, out_prefix)\n",
    "\n",
    "print(\"\\n✅ DONE. Output directory:\")\n",
    "print(SAVE_ROOT_I)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
