import os
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import timm
from tqdm import tqdm

# ì„¤ì •
CACHE_DIR = "./slice_cache0_224"
MODEL_DIR = "./models/beit0"
CSV_PATH = "./cx.csv"
FEATURE_DIR = "./features/beit0_features"
NUM_RUNS = 30
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ë””ë ‰í† ë¦¬ ì¤€ë¹„
os.makedirs(FEATURE_DIR, exist_ok=True)

# ëª¨ë¸ ì •ì˜ (BEiT ë°±ë³¸ ì‚¬ìš©)
class BEiTBackbone(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = timm.create_model("beit_base_patch16_224", pretrained=False, num_classes=0)

    def forward(self, x):
        return self.backbone(x)  # (B, D)

# DataFrame ë¡œë”©
df = pd.read_csv(CSV_PATH)
df = df[df['PatientID'].str.contains('pre')]
df = df[df['PatientID'].apply(lambda x: os.path.exists(os.path.join(CACHE_DIR, f"{x}.pt")))]
df = df.reset_index(drop=True)

print(f"\nğŸ‘‰ [DEBUG] ìµœì¢… df PatientID ìˆ˜: {len(df)}")
if len(df) > 0:
    print(df["PatientID"].head())
else:
    print("âš ï¸ df ê°€ ë¹„ì–´ìˆìŒ! â†’ CSV ë˜ëŠ” ìºì‹œ í™•ì¸ í•„ìš”")

# ì „ì²´ Run ë°˜ë³µ
for run in range(NUM_RUNS):
    print(f"\nğŸš€ Run {run}/{NUM_RUNS} â†’ Feature ì¶”ì¶œ ì‹œì‘...")

    model_path = os.path.join(MODEL_DIR, f"best_model_beit_run{run}.pt")
    if not os.path.exists(model_path):
        print(f"âŒ Run {run} ëª¨ë¸ ì—†ìŒ â†’ skip: {model_path}")
        continue

    # ëª¨ë¸ ë¡œë”©
    model = BEiTBackbone().to(DEVICE)
    state_dict = torch.load(model_path, map_location=DEVICE, weights_only=False)["state_dict"]
    model.backbone.load_state_dict(
        {k.replace("backbone.", ""): v for k, v in state_dict.items() if k.startswith("backbone.")}, strict=False
    )
    model.eval()

    # í”¼ì²˜ ì¶”ì¶œ
    features = []
    with torch.no_grad():
        for _, row in tqdm(df.iterrows(), total=len(df)):
            pid = row["PatientID"]
            cache_path = os.path.join(CACHE_DIR, f"{pid}.pt")
            if not os.path.exists(cache_path):
                print(f"âš ï¸ {pid} ìºì‹œ ì—†ìŒ â†’ skip")
                continue
            imgs = torch.load(cache_path).to(DEVICE)  # (20, 3, 224, 224)
            if imgs.shape[1] == 1:
                imgs = imgs.repeat(1, 3, 1, 1)
            feats = model(imgs)  # (20, D)
            mean_feat = feats.mean(dim=0).cpu().numpy()
            features.append([pid] + mean_feat.tolist())

    # ì €ì¥
    if features:
        feature_dim = len(features[0]) - 1
        columns = ["PatientID"] + [f"feat_{i}" for i in range(feature_dim)]
        df_feat = pd.DataFrame(features, columns=columns)
        save_path = os.path.join(FEATURE_DIR, f"beit_base_patch16_224_backbone_features_run{run}.csv")
        df_feat.to_csv(save_path, index=False)
        print(f"âœ… Run {run} Feature ì €ì¥ ì™„ë£Œ â†’ {save_path}")
    else:
        print(f"âš ï¸ Run {run} â†’ ì¶”ì¶œëœ feature ì—†ìŒ â†’ ì €ì¥ skip")

# ë³‘í•©
print("\nğŸ“¢ ì „ì²´ Run Feature ë³‘í•© ì‹œì‘...")
dfs = []
for run in range(NUM_RUNS):
    file_path = os.path.join(FEATURE_DIR, f"beit_base_patch16_224_backbone_features_run{run}.csv")
    if os.path.exists(file_path):
        df_run = pd.read_csv(file_path)
        df_run["Run"] = run
        dfs.append(df_run)
    else:
        print(f"âš ï¸ Run {run} feature íŒŒì¼ ì—†ìŒ â†’ skip")

if dfs:
    df_merged = pd.concat(dfs, ignore_index=True)
    merged_path = os.path.join(FEATURE_DIR, "beit_base_patch16_224_backbone_features_merged.csv")
    df_merged.to_csv(merged_path, index=False)
    print(f"ğŸ‰ ì „ì²´ Feature ë³‘í•© ì €ì¥ ì™„ë£Œ â†’ {merged_path}")
    print("\nğŸ“Š Runë³„ Patient ìˆ˜:")
    print(df_merged['Run'].value_counts().sort_index())
else:
    print("âš ï¸ ë³‘í•©í•  Feature íŒŒì¼ì´ ì—†ìŒ!")
