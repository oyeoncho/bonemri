# Pelvic Bone MRI Survival â€“ Code Repository

> End-to-end code and notebooks for **deep learningâ€“based radiomics of pelvic bone T1â€‘weighted MRI** and survival prediction with a **Mixture Stretchedâ€‘Exponential (Mixtureâ€‘SE)** model.

This README summarizes how to set up the environment, prepare data, reproduce the main experiments (Model A / Model B), select robust features across BEiT variants, run external validation, and generate visualizations.

> ðŸ“„ Related manuscript: â€œDeep Learningâ€“Based Radiomics of Pelvic Bone T1â€‘weighted MRI for Cervical Cancer Survival Prediction Using a Mixture Stretchedâ€‘Exponential Model.â€  (Please cite when using this code.)

---

## 1) Repository Map (top-level)

```
code_paper/
â”œâ”€ environment.json
â”œâ”€ environment.txt
â”œâ”€ nvidia-smi.txt
â”œâ”€ pip-freeze.txt
â”œâ”€ external/                    # External validation & cohort harmonization (R, ipynb)
â”‚  â”œâ”€ ex_analysis.R
â”‚  â”œâ”€ ex_integrate.R
â”‚  â”œâ”€ ex_test.ipynb
â”‚  â”œâ”€ preprocessing.ipynb
â”‚  â””â”€ ...
â”œâ”€ feature_selection/           # Feature recurrence & refinement across runs/variants (R)
â”‚  â”œâ”€ selection1.R
â”‚  â””â”€ selection2.R
â”œâ”€ generalizable_analysis/      # Cross-variant common-feature analysis (R)
â”‚  â””â”€ overlap_features_analysis.R
â”œâ”€ each_group/                  # Perâ€‘group utilities (R)
â”‚  â””â”€ ...
â”œâ”€ interpretation/              # Imaging attention & molecular links (R)
â”‚  â””â”€ interpretation.R
â”œâ”€ IXI_pretrain/                # Domain-adaptive pretraining utilities / notes (ipynb)
â”‚  â””â”€ _pretrained_models.ipynb
â”œâ”€ make_cache/                  # Caching helpers for preprocessing/features (py)
â”‚  â””â”€ make_cache.py (if present)
â”œâ”€ beit0.py                     # Model A config: native 224Ã—224, domain-adapted BEiT
â”œâ”€ beit.py                      # Model A config: 196â†’224 padded, domain-adapted BEiT
â”œâ”€ beit_resize.py               # Model A config: 196â†’224 resized, domain-adapted BEiT
â”œâ”€ beit0_o/                     # ImageNet-only pretrain (no domain adaptation), native
â”œâ”€ beit_o/                      # ImageNet-only, padded
â”œâ”€ beit_resize_o/               # ImageNet-only, resized
â”œâ”€ beit1/                       # Inferior 20-slice variant (domain-adapted)
â”œâ”€ model_A_backbone_extract/    # Slice encoder & feature extraction
â”‚  â””â”€ beit/
â”‚     â”œâ”€ beit_extract.py        # Extract 768-dim slice features; averageâ†’patient vector
â”‚     â””â”€ beit.py                # Model A core (blocks 4â€“11 fine-tuned)
â”œâ”€ model_B/                     # Survival heads
â”‚  â”œâ”€ model_B.ipynb             # Mixtureâ€‘SE training/eval (image / clinical / combined)
â”‚  â””â”€ cox_model_B_analysis.R    # CoxPH benchmarking
â”œâ”€ preprocessing/               # MRI & mask preprocessing (ipynb)
â”‚  â””â”€ preprocessing.ipynb
â”œâ”€ synthetic_benchmark/         # Simulation study
â”‚  â”œâ”€ synthetic_benchmark.ipynb
â”‚  â””â”€ synthetic_analysis.R
â”œâ”€ visualization/               # Attention maps & activation differences (py)
â”‚  â”œâ”€ activation_diff.py
â”‚  â”œâ”€ patch_level_attention.py
â”‚  â”œâ”€ simlav.py / vis.py (if present)
â”‚  â””â”€ ...
â””â”€ README.md
```

> The exact filenames may differ slightly by commit; use the closest variant if you donâ€™t see an exact match.

---

## 2) Environment

- **Python** â‰¥ 3.10, **CUDA** (optional, recommended)
- Install from snapshot:
  ```bash
  # suggested: create a clean env first, then:
  pip install -r environment.txt
  # or replicate fully:
  pip install -r pip-freeze.txt
  ```
- For GPU diagnostics see `nvidia-smi.txt`.
- R scripts require **R â‰¥ 4.2** with the tidyverse ecosystem.

---

## 3) Data Layout (expected)

- **Inputs**
  - Pretreatment **T1â€‘weighted pelvic MRI** per patient.
  - Corresponding **pelvic bone masks** (NIfTI). (Masks can be generated via the paperâ€™s pseudoâ€‘labeling pipeline; see notes in `preprocessing/`.)
- **Preprocessing** (performed in `preprocessing/preprocessing.ipynb`):
  - N4 bias correction, Zâ€‘score normalization.
  - Resample to **1.0Ã—1.0Ã—1.0 mm**.
  - Crop/pad to **[128, 224, 224]** (or **[128, 196, 196]** depending on variant).
  - Extract **20 slices** (central or inferior set by variant) **within the bone mask**.

> External cohorts with heterogeneous FOVs should be resampled to a fixed **physical FOV 224Ã—224Ã—128 mmÂ³** to ensure complete pelvic coverage (see `external/` notes).

---

## 4) BEiT Variants (ModelÂ A)

| Variant dir/file | Resize strategy | Pretraining |
|---|---|---|
| `beit0.py`       | **Native 224Ã—224** (no resize) | **Domainâ€‘adaptive** (ImageNetâ†’IXI T1) |
| `beit.py`        | **196â†’224 padded** (no stretch) | **Domainâ€‘adaptive** |
| `beit_resize.py` | **196â†’224 resized** (stretched) | **Domainâ€‘adaptive** |
| `beit0_o/`       | Native 224Ã—224 | ImageNetâ€‘only |
| `beit_o/`        | 196â†’224 padded | ImageNetâ€‘only |
| `beit_resize_o/` | 196â†’224 resized | ImageNetâ€‘only |
| `beit1/`         | **Inferior 20 slices** (native 224) | Domainâ€‘adaptive |

Each ModelÂ A run encodes 20 masked slices with BEiT â†’ **768â€‘dim** slice features â†’ **patientâ€‘level average** vector. During fineâ€‘tuning, only **BEiT blocks 4â€“11** are updated to preserve pretraining.

**Run ModelÂ A (example)**

```bash
# Example: domainâ€‘adapted, native 224
python model_A_backbone_extract/beit/beit_extract.py   --variant beit0   --images /path/to/mri/   --masks  /path/to/masks/   --outdir ./features/beit0/run_XX/
```

- Repeat **30Ã—** (different seeds) per variant. Each run saves:
  - patientâ€‘level features (CSV or NPZ),
  - split indices (train/val),
  - logs/plots.

---

## 5) Feature Refinement (recurrence across runs)

1. For each run, compute survival correlation and keep **topâ€‘100** backbone features.
2. Stack across 30 runs (**3,000** entries) and form **nX** groups = features recurring â‰¥ **X** times (X=4..9).
3. Use **`feature_selection/selection1.R`** and **`selection2.R`** to materialize refined sets.
4. **`generalizable_analysis/overlap_features_analysis.R`** derives **common features across BEiT variants** (nested: **n4 âŠƒ n5 âŠƒ n6 âŠƒ n7**).

---

## 6) Survival Modeling (ModelÂ B) & Baselines

- **ModelÂ B (Mixtureâ€‘SE)** â€” Train on refined features (imageâ€‘only, clinicalâ€‘only, or combined):
  - Notebook: `model_B/model_B.ipynb`
  - Repeats **30Ã—** (70/30 MCâ€‘CV). Primary metric: **mean Câ€‘index** over {12,24,36,48,60,72} months.
- **CoxPH baseline** â€” `model_B/cox_model_B_analysis.R`
- Outputs:
  - Perâ€‘run metrics (AUC, Câ€‘index), distribution plots, and tables.

**CLIâ€‘style pseudocode**

```bash
# Mixtureâ€‘SE (imageâ€‘only)
jupyter nbconvert --to notebook --execute model_B/model_B.ipynb   --TagRemovePreprocessor.remove_input_tags='["long-run"]'   --output outputs/model_B_mixtureSE_image_only.ipynb
```

---

## 7) External Validation

- Data harmonization & followâ€‘up definitions: `external/` (R & ipynb).
- Ensure resampling to **224Ã—224Ã—128 mmÂ³** physical FOV before slice extraction.
- Reuse internal **runâ€‘specific indices** (n4â€“n7) to extract matching features from external patients.
- Evaluate with the same MCâ€‘CV protocol (30Ã—) and report **Câ€‘index/AUC**.

---

## 8) Visualization & Interpretation

- **Patchâ€‘level attention**: `visualization/patch_level_attention.py`
- **Group activation differences** (e.g., >60â€‘month survivors vs <12â€‘month deaths): `visualization/activation_diff.py`
- **Molecular associations** (exosomal RNA / CBC): `interpretation/interpretation.R`

---

## 9) Synthetic Benchmark (optional but recommended)

- Reproduce Fig.Â 2â€‘style comparisons (Mixtureâ€‘SE vs CoxPH/WeibullAFT/DeepSurv):
  - `synthetic_benchmark/synthetic_benchmark.ipynb`
  - `synthetic_benchmark/synthetic_analysis.R`

---

## 10) Endâ€‘toâ€‘End Quickstart

```bash
# 0) Create env
pip install -r environment.txt

# 1) Preprocess MRI + masks
jupyter lab preprocessing/preprocessing.ipynb

# 2) Train Model A (30 runs) for chosen BEiT variants
python model_A_backbone_extract/beit/beit_extract.py --variant beit0 ...

# 3) Select recurrent features (n4â€“n7) per variant
Rscript feature_selection/selection1.R
Rscript feature_selection/selection2.R

# 4) Derive crossâ€‘variant common features
Rscript generalizable_analysis/overlap_features_analysis.R

# 5) Train Model B (Mixtureâ€‘SE) on refined/common features
jupyter lab model_B/model_B.ipynb

# 6) Benchmark with CoxPH
Rscript model_B/cox_model_B_analysis.R

# 7) External validation
jupyter lab external/ex_analysis.R  # or run via RStudio
```

---

## 11) Key Results (for orientation)

- **Internal validation (imageâ€‘only)**: mean **Câ€‘index â‰ˆ 0.829**, **AUC â‰ˆ 0.852** across runs; adding clinical variables did **not** significantly improve overall survival prediction.
- **External validation (TCGAâ€‘CESC, CCRTâ€‘only)**: **Câ€‘index â‰ˆ 0.703**, **AUC â‰ˆ 0.732** (imageâ€‘only, n4â€“n7); **n7** (2 features) reached **Câ€‘index â‰ˆ 0.744**, **AUC â‰ˆ 0.803**, comparable to image+clinical.

See manuscript for full statistics and confidence intervals.

---

## 12) Tips & Troubleshooting

- **Slice coverage**: If the left/right pelvis is cut off, increase FOV or adjust centering before cropping to [128,224,224].
- **Reproducibility**: Fix seeds per run; log train/val splits.
- **Overfitting**: Prefer **n6/n7** in very small external cohorts to keep eventsâ€‘perâ€‘variable reasonable.
- **Domain adaptation**: Models with **IXI T1** domainâ€‘adaptive pretraining tend to yield more reproducible features and cleaner attention maps.

---

## 13) Citation

If you use this code, please cite the accompanying manuscript.

Cho O, El Naqa I. *Deep Learningâ€“Based Radiomics of Pelvic Bone T1â€‘weighted MRI for Cervical Cancer Survival Prediction Using a Mixture Stretchedâ€‘Exponential Model.*

---

## 14) License

Unless specified elsewhere, this code is released for **research use**. Please contact the authors for other uses.

---

## 15) Acknowledgments

Thanks to collaborators and the institutions supporting this work.
