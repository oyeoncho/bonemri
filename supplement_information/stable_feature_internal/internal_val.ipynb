{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixture Stretched Exponential Survival with Debugging and NaN Handling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lifelines.utils import concordance_index\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ‚úÖ Ï†ÑÏó≠ Ïû¨ÌòÑÏÑ± Í≥†Ï†ïÏö© Í∏∞Î≥∏ ÏãúÎìú\n",
    "BASE_SEED = 20250903\n",
    "# Seed Í≥†Ï†ï\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "# Î™®Îç∏ Ï†ïÏùò\n",
    "class MixtureStretchedExponentialSurvival(nn.Module):\n",
    "    def __init__(self, input_dim, num_components=2):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.ReLU()\n",
    "        )\n",
    "        self.pi_layer = nn.Linear(64, num_components)\n",
    "        self.lam_layer = nn.Linear(64, num_components)\n",
    "        self.alpha_layer = nn.Linear(64, num_components)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        pi = F.softmax(self.pi_layer(h), dim=1)\n",
    "        lam = F.softplus(self.lam_layer(h)) + 1e-3\n",
    "        a = F.softplus(self.alpha_layer(h)) + 1e-3\n",
    "        return pi, lam, a\n",
    "\n",
    "# Loss Ï†ïÏùò\n",
    "def mixture_stretched_nll(t, e, pi, lam, a, eps=1e-8):\n",
    "    t = t.view(-1, 1)\n",
    "    t_a = torch.pow(t + eps, a)\n",
    "    S_k = torch.exp(-lam * t_a)\n",
    "    f_k = lam * a * torch.pow(t + eps, a - 1) * S_k\n",
    "    f = torch.sum(pi * f_k, dim=1) + eps\n",
    "    S = torch.sum(pi * S_k, dim=1) + eps\n",
    "    loglik = e * torch.log(f) + (1 - e) * torch.log(S)\n",
    "    return -loglik.mean()\n",
    "\n",
    "# ÏÉùÏ°¥Í≥°ÏÑ† ÏòàÏ∏°\n",
    "@torch.no_grad()\n",
    "def predict_survival(model, x, times):\n",
    "    model.eval()\n",
    "    pi, lam, a = model(x)\n",
    "    surv = []\n",
    "    for t in times:\n",
    "        t_tensor = torch.tensor([t], dtype=torch.float32, device=x.device)\n",
    "        t_a = torch.pow(t_tensor + 1e-8, a)\n",
    "        S_k = torch.exp(-lam * t_a)\n",
    "        S = torch.sum(pi * S_k, dim=1)\n",
    "        surv.append(S.cpu().numpy())\n",
    "    return np.vstack(surv)\n",
    "\n",
    "# AUC Í≥ÑÏÇ∞\n",
    "def calc_auc(surv_arr, y_df, times):\n",
    "    aucs = {}\n",
    "    for i, t in enumerate(times):\n",
    "        true = ((y_df[\"event\"] == 1) & (y_df[\"time\"] <= t)).astype(int)\n",
    "        pred = 1 - surv_arr[i, :]\n",
    "        try:\n",
    "            aucs[t] = roc_auc_score(true, pred)\n",
    "        except:\n",
    "            aucs[t] = np.nan\n",
    "    return aucs\n",
    "\n",
    "# ÏïàÏ†ïÏ†ÅÏù∏ C-index Í≥ÑÏÇ∞\n",
    "def safe_concordance_index(times, risks, events):\n",
    "    times = np.asarray(times)\n",
    "    risks = np.asarray(risks)\n",
    "    events = np.asarray(events)\n",
    "    mask = ~(np.isnan(times) | np.isnan(risks) | np.isnan(events))\n",
    "    if np.sum(mask) < 2:\n",
    "        print(\"‚ö†Ô∏è Too few valid samples for C-index:\", np.sum(mask))\n",
    "        return np.nan\n",
    "    if np.std(risks[mask]) < 1e-6:\n",
    "        print(\"‚ö†Ô∏è Low risk variance, skipping C-index\")\n",
    "        return np.nan\n",
    "    return concordance_index(times[mask], risks[mask], events[mask])\n",
    "\n",
    "\n",
    "os.makedirs(\"./survival_model/mixture_non_fix/models\", exist_ok=True)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "BASE_GROUPS = [\"beit0\"]\n",
    "N_RUNS = 30\n",
    "time_points = [12, 24, 36, 48, 60, 72]\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "# ‚úÖ Í∑∏Î£πÎ≥Ñ img_cols Ï†ïÏùò\n",
    "GROUP_IMG_COLS = {\n",
    "    \"n4_30_30\": [\n",
    "        \"feat_10\", \"feat_15\", \"feat_25\", \"feat_121\", \"feat_123\", \"feat_125\", \"feat_143\", \"feat_152\", \"feat_163\", \"feat_167\",\n",
    "        \"feat_169\", \"feat_181\", \"feat_194\", \"feat_203\", \"feat_210\", \"feat_220\", \"feat_240\", \"feat_255\", \"feat_289\", \"feat_309\",\n",
    "        \"feat_328\", \"feat_352\", \"feat_361\", \"feat_368\", \"feat_378\", \"feat_389\", \"feat_402\", \"feat_407\", \"feat_420\", \"feat_439\",\n",
    "        \"feat_451\", \"feat_468\", \"feat_498\", \"feat_507\", \"feat_514\", \"feat_560\", \"feat_565\", \"feat_576\", \"feat_578\", \"feat_605\",\n",
    "        \"feat_617\", \"feat_633\", \"feat_653\", \"feat_656\", \"feat_666\", \"feat_710\", \"feat_747\"\n",
    "    ],\n",
    "    \"n5_30_30\": [\n",
    "        \"feat_2\", \"feat_55\", \"feat_80\", \"feat_107\", \"feat_109\", \"feat_137\", \"feat_173\", \"feat_209\", \"feat_223\", \"feat_327\",\n",
    "        \"feat_374\", \"feat_391\", \"feat_499\", \"feat_554\", \"feat_577\", \"feat_583\", \"feat_657\", \"feat_715\"\n",
    "    ],\n",
    "    \"n6_30_30\": [\n",
    "        \"feat_213\", \"feat_266\", \"feat_215\"\n",
    "    ],\n",
    "    \"n7_30_30\": [\n",
    "        \"feat_436\", \"feat_519\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Í≥µÌÜµ clinical Î≥ÄÏàò\n",
    "cont_cols = ['Age']\n",
    "cat_cols  = ['pathology', 'stage0']\n",
    "\n",
    "for base_group in BASE_GROUPS:\n",
    "    print(f\"\\n\\n============================\")\n",
    "    print(f\"üìÅ BEiT Í∑∏Î£π Ïã§Ìñâ Ï§ë: {base_group}\")\n",
    "    print(f\"============================\")\n",
    "\n",
    "    # üîÅ n4/n5/n6/n7 Í∑∏Î£πÏùÑ ÏàúÌöå\n",
    "    for GROUP, img_cols in GROUP_IMG_COLS.items():\n",
    "        print(f\"\\n========== GROUP: {GROUP} ==========\")\n",
    "\n",
    "        SAVE_ROOT_BASE = f\"./survival_model/mixture_non_fix/non_nest/{base_group}/results/generalization/test0/dl0/{GROUP}\"\n",
    "        os.makedirs(SAVE_ROOT_BASE, exist_ok=True)\n",
    "        SAVE_ROOT = SAVE_ROOT_BASE\n",
    "\n",
    "        for i in range(1, N_RUNS + 1):\n",
    "            fname = f\"dh11_run{i:02d}.csv\"\n",
    "            csv_path = f\"./deephit/{base_group}/test/dl0/{GROUP}/{fname}\"\n",
    "            print(f\"\\nüöÄ Ïã§Ìñâ Ï§ë: {base_group} - {GROUP} - {fname}\")\n",
    "\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"‚ö†Ô∏è ÌååÏùº ÏóÜÏùå, Ïä§ÌÇµ: {csv_path}\")\n",
    "                continue\n",
    "\n",
    "            # === Ïó¨Í∏∞ÏÑúÎ∂ÄÌÑ∞Îäî Í∏∞Ï°¥ i-loop ÎÇ¥Î∂Ä ÏΩîÎìúÏôÄ ÎèôÏùº ===\n",
    "            df_all = pd.read_csv(csv_path)\n",
    "            df_all['event'] = df_all['survival'].astype(bool)\n",
    "            df_all['time']  = df_all['fu_date'].astype(np.float32)\n",
    "\n",
    "            feature_sets = {\n",
    "                'Image only': (img_cols, []),\n",
    "                'Clinical only': ([], cont_cols + cat_cols),\n",
    "                'Image + Clinical': (img_cols, cont_cols + cat_cols)\n",
    "            }\n",
    "\n",
    "            results_dict = {}\n",
    "            raw_rows_auc, raw_rows_cidx = [], []\n",
    "\n",
    "            for label, (img_part, clinical_part) in feature_sets.items():\n",
    "                print(f\"\\nüìå Feature Set: {label}\")\n",
    "                auc_train_list, auc_val_list = [], []\n",
    "                cidx_train_list, cidx_val_list = [], []\n",
    "\n",
    "                for run in range(N_RUNS):\n",
    "                    seed = BASE_SEED + run\n",
    "                    set_seed(seed)\n",
    "\n",
    "                    X_df = df_all[img_part + clinical_part].copy()\n",
    "                    y_df = df_all[['time', 'event']].copy()\n",
    "\n",
    "                    X_train_df, X_val_df, y_train, y_val = train_test_split(\n",
    "                        X_df, y_df,\n",
    "                        test_size=0.3,\n",
    "                        random_state=seed  # ‚úÖ BASE_SEED+run ÏÇ¨Ïö©\n",
    "                    )\n",
    "\n",
    "                    transformers = []\n",
    "                    if img_part:\n",
    "                        transformers.append(('img', StandardScaler(), img_part))\n",
    "                    cont = [c for c in clinical_part if c in cont_cols]\n",
    "                    cat  = [c for c in clinical_part if c in cat_cols]\n",
    "                    if cont:\n",
    "                        transformers.append(('cont', StandardScaler(), cont))\n",
    "                    if cat:\n",
    "                        transformers.append(('cat', OneHotEncoder(sparse_output=False,\n",
    "                                                                  handle_unknown='ignore'),\n",
    "                                             cat))\n",
    "\n",
    "                    ct = ColumnTransformer(transformers)\n",
    "                    X_train = ct.fit_transform(X_train_df)\n",
    "                    X_val   = ct.transform(X_val_df)\n",
    "\n",
    "                    X_train = pd.DataFrame(X_train).fillna(0).values.astype(np.float32)\n",
    "                    X_val   = pd.DataFrame(X_val).fillna(0).values.astype(np.float32)\n",
    "\n",
    "                    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(DEVICE)\n",
    "                    X_val_tensor   = torch.tensor(X_val,   dtype=torch.float32).to(DEVICE)\n",
    "                    t_train = torch.tensor(y_train['time'].values,  dtype=torch.float32).to(DEVICE)\n",
    "                    e_train = torch.tensor(y_train['event'].values, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "                    model = MixtureStretchedExponentialSurvival(\n",
    "                        input_dim=X_train.shape[1],\n",
    "                        num_components=2\n",
    "                    ).to(DEVICE)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "                    best_val_loss = float('inf')\n",
    "                    patience, patience_counter = 10, 0\n",
    "                    best_model_state = None\n",
    "\n",
    "                    for epoch in range(1000):\n",
    "                        model.train()\n",
    "                        optimizer.zero_grad()\n",
    "                        pi, lam, a = model(X_train_tensor)\n",
    "                        loss = mixture_stretched_nll(t_train, e_train, pi, lam, a)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if loss.item() < best_val_loss - 1e-6:\n",
    "                            best_val_loss = loss.item()\n",
    "                            best_model_state = model.state_dict()\n",
    "                            patience_counter = 0\n",
    "                        else:\n",
    "                            patience_counter += 1\n",
    "                            if patience_counter >= patience:\n",
    "                                break\n",
    "\n",
    "                    if best_model_state:\n",
    "                        model.load_state_dict(best_model_state)\n",
    "\n",
    "                    surv_train = predict_survival(model, X_train_tensor, time_points)\n",
    "                    surv_val   = predict_survival(model, X_val_tensor,   time_points)\n",
    "\n",
    "                    auc_train = calc_auc(surv_train, y_train.reset_index(drop=True), time_points)\n",
    "                    auc_val   = calc_auc(surv_val,   y_val.reset_index(drop=True),   time_points)\n",
    "                    auc_train_list.append(auc_train)\n",
    "                    auc_val_list.append(auc_val)\n",
    "\n",
    "                    risk_train = surv_train.T\n",
    "                    risk_val   = surv_val.T\n",
    "                    cidx_train = [safe_concordance_index(y_train['time'], risk_train[:, j], y_train['event'])\n",
    "                                  for j in range(len(time_points))]\n",
    "                    cidx_val   = [safe_concordance_index(y_val['time'],   risk_val[:,   j], y_val['event'])\n",
    "                                  for j in range(len(time_points))]\n",
    "                    cidx_train_list.append(cidx_train)\n",
    "                    cidx_val_list.append(cidx_val)\n",
    "\n",
    "                    for j, t in enumerate(time_points):\n",
    "                        raw_rows_auc.append({\n",
    "                            \"Feature Set\": label, \"Run\": run,\n",
    "                            \"Time (Months)\": t,\n",
    "                            \"AUC (Train)\": auc_train[t],\n",
    "                            \"AUC (Val)\":   auc_val[t],\n",
    "                            \"Scope\": \"Time-wise\"\n",
    "                        })\n",
    "                        raw_rows_cidx.append({\n",
    "                            \"Feature Set\": label, \"Run\": run,\n",
    "                            \"Time (Months)\": t,\n",
    "                            \"C-index (Train)\": cidx_train[j],\n",
    "                            \"C-index (Val)\":   cidx_val[j],\n",
    "                            \"Scope\": \"Time-wise\"\n",
    "                        })\n",
    "\n",
    "                    raw_rows_auc.append({\n",
    "                        \"Feature Set\": label, \"Run\": run,\n",
    "                        \"Time (Months)\": \"Overall\",\n",
    "                        \"AUC (Train)\": np.nanmean(list(auc_train.values())),\n",
    "                        \"AUC (Val)\":   np.nanmean(list(auc_val.values())),\n",
    "                        \"Scope\": \"Overall\"\n",
    "                    })\n",
    "                    raw_rows_cidx.append({\n",
    "                        \"Feature Set\": label, \"Run\": run,\n",
    "                        \"Time (Months)\": \"Overall\",\n",
    "                        \"C-index (Train)\": np.nanmean(cidx_train),\n",
    "                        \"C-index (Val)\":   np.nanmean(cidx_val),\n",
    "                        \"Scope\": \"Overall\"\n",
    "                    })\n",
    "\n",
    "                results_dict[label] = {\n",
    "                    'mean_auc_train': {t: np.nanmean([r[t] for r in auc_train_list]) for t in time_points},\n",
    "                    'mean_auc_val':   {t: np.nanmean([r[t] for r in auc_val_list])   for t in time_points},\n",
    "                    'std_auc_train':  {t: np.nanstd([r[t] for r in auc_train_list])  for t in time_points},\n",
    "                    'std_auc_val':    {t: np.nanstd([r[t] for r in auc_val_list])    for t in time_points},\n",
    "                    'mean_cidx_train':{t: np.nanmean([r[j] for r in cidx_train_list]) for j, t in enumerate(time_points)},\n",
    "                    'mean_cidx_val':  {t: np.nanmean([r[j] for r in cidx_val_list])   for j, t in enumerate(time_points)},\n",
    "                    'std_cidx_train': {t: np.nanstd([r[j] for r in cidx_train_list])  for j, t in enumerate(time_points)},\n",
    "                    'std_cidx_val':   {t: np.nanstd([r[j] for r in cidx_val_list])    for j, t in enumerate(time_points)}\n",
    "                }\n",
    "\n",
    "            # Í≤∞Í≥º Ï†ÄÏû• (GROUP + i Ï°∞Ìï©Î≥Ñ)\n",
    "            raw_auc_path  = os.path.join(SAVE_ROOT, f\"raw_auc_per_time_run{i:02d}.csv\")\n",
    "            raw_cidx_path = os.path.join(SAVE_ROOT, f\"raw_cindex_per_time_run{i:02d}.csv\")\n",
    "            pd.DataFrame(raw_rows_auc).to_csv(raw_auc_path, index=False)\n",
    "            pd.DataFrame(raw_rows_cidx).to_csv(raw_cidx_path, index=False)\n",
    "            print(f\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å: GROUP={GROUP}, run{i:02d}\")\n",
    "\n",
    "            # ÏãúÍ∞ÅÌôî Ï†ÄÏû• (AUC)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            for label in feature_sets:\n",
    "                plt.errorbar(time_points, list(results_dict[label]['mean_auc_train'].values()),\n",
    "                             yerr=list(results_dict[label]['std_auc_train'].values()),\n",
    "                             fmt='--o', capsize=4, label=f\"{label} - AUC Train\")\n",
    "                plt.errorbar(time_points, list(results_dict[label]['mean_auc_val'].values()),\n",
    "                             yerr=list(results_dict[label]['std_auc_val'].values()),\n",
    "                             fmt='-o', capsize=4, label=f\"{label} - AUC Val\")\n",
    "            plt.title(f\"AUC (GROUP {GROUP}, File run{i:02d})\")\n",
    "            plt.xlabel(\"Time (Months)\")\n",
    "            plt.ylabel(\"AUC\")\n",
    "            plt.ylim(0.1, 1.0)\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(SAVE_ROOT, f\"plot_auc_run{i:02d}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            # ÏãúÍ∞ÅÌôî Ï†ÄÏû• (C-index)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            for label in feature_sets:\n",
    "                plt.errorbar(time_points, list(results_dict[label]['mean_cidx_train'].values()),\n",
    "                             yerr=list(results_dict[label]['std_cidx_train'].values()),\n",
    "                             fmt='--s', capsize=4, label=f\"{label} - C-index Train\")\n",
    "                plt.errorbar(time_points, list(results_dict[label]['mean_cidx_val'].values()),\n",
    "                             yerr=list(results_dict[label]['std_cidx_val'].values()),\n",
    "                             fmt='-s', capsize=4, label=f\"{label} - C-index Val\")\n",
    "            plt.title(f\"C-index (GROUP {GROUP}, File run{i:02d})\")\n",
    "            plt.xlabel(\"Time (Months)\")\n",
    "            plt.ylabel(\"C-index\")\n",
    "            plt.ylim(0.1, 1.0)\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(SAVE_ROOT, f\"plot_cindex_run{i:02d}.png\"))\n",
    "            plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
