import os
import torch
import nibabel as nib
import numpy as np
import pandas as pd
from tqdm import tqdm
from PIL import Image
from torchvision import transforms

# -----------------------------
# ì„¤ì •
# -----------------------------
IMAGE_DIR = "./image_data/output_224/images"
MASK_DIR = "./image_data/output_224/masks"
SAVE_DIR = "./slice_cache0_224"  # âœ… í´ë”ëª… ìœ ì§€
MAX_SLICES = 20
VALID_AREA_THRESHOLD = 50
MODEL_RESOLUTION = None  # (H, W) ìœ ì§€. í•„ìš”ì‹œ (224, 224) ë“± ì„¤ì • ê°€ëŠ¥

os.makedirs(SAVE_DIR, exist_ok=True)

# -----------------------------
# í•¨ìˆ˜ ì •ì˜
# -----------------------------
def slice_to_tensor(slice_2d):
    # 1) Min-max ì •ê·œí™” (0â€“255)
    normed = (slice_2d - np.min(slice_2d)) / (np.ptp(slice_2d) + 1e-6)
    img = Image.fromarray(np.uint8(normed * 255)).convert("RGB")  # 3ì±„ë„ ë³µì œ

    # 2) ë¦¬ì‚¬ì´ì¦ˆ(ì˜µì…˜) + í…ì„œí™” + ImageNet ì •ê·œí™”
    if MODEL_RESOLUTION:
        img = transforms.Resize(MODEL_RESOLUTION)(img)

    transform = transforms.Compose([
        transforms.ToTensor(),  # (H, W, 3) â†’ (3, H, W), [0,1]
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])  # ImageNet
    ])
    return transform(img)

def extract_center_masked_slices(vol, mask, valid_area_threshold=VALID_AREA_THRESHOLD):
    """
    ë§ˆìŠ¤í¬ ìœ íš¨ ë©´ì (>= threshold)ì¸ ìŠ¬ë¼ì´ìŠ¤ë§Œ ëª¨ì•„,
    - ê°œìˆ˜ê°€ 20 ì´ìƒì´ë©´ ì¤‘ì•™ ê¸°ì¤€ 20ì¥
    - ì ìœ¼ë©´ ì¢Œ/ìš° ê· ë“± íŒ¨ë”© í›„ 20ì¥
    """
    mask = (mask > 0).astype(np.float32)
    valid_slices = []
    for i in range(vol.shape[2]):
        m = mask[:, :, i]
        if np.sum(m) >= valid_area_threshold:
            valid_slices.append(vol[:, :, i] * m)

    num_valid = len(valid_slices)
    H, W = vol.shape[0], vol.shape[1]
    zero_slice = np.zeros((H, W), dtype=vol.dtype)

    if num_valid == 0:
        return [zero_slice] * MAX_SLICES, num_valid

    if num_valid >= MAX_SLICES:
        center = num_valid // 2
        half = MAX_SLICES // 2
        start = max(0, center - half)
        end = start + MAX_SLICES
        if end > num_valid:  # ê²½ê³„ ë³´ì •
            end = num_valid
            start = end - MAX_SLICES
        selected = valid_slices[start:end]
    else:
        pad_left = (MAX_SLICES - num_valid) // 2
        pad_right = MAX_SLICES - num_valid - pad_left
        selected = [zero_slice] * pad_left + valid_slices + [zero_slice] * pad_right

    return selected, num_valid

def process_patient(pid):
    img_path = os.path.join(IMAGE_DIR, f"{pid}.nii.gz")
    mask_path = os.path.join(MASK_DIR, f"{pid}.nii.gz")

    if not (os.path.exists(img_path) and os.path.exists(mask_path)):
        return None

    vol = nib.load(img_path).get_fdata().astype(np.float32)   # (H, W, Z)
    mask = nib.load(mask_path).get_fdata().astype(np.float32) # (H, W, Z)

    slices, valid_count = extract_center_masked_slices(vol, mask)

    tensors = torch.stack([slice_to_tensor(s) for s in slices])  # (20, 3, H, W) or (20, 3, *MODEL_RESOLUTION)
    torch.save(tensors, os.path.join(SAVE_DIR, f"{pid}.pt"))
    return pid, valid_count

# -----------------------------
# ì‹¤í–‰
# -----------------------------
all_pids = [
    f.replace(".nii.gz", "")
    for f in os.listdir(IMAGE_DIR)
    if f.endswith(".nii.gz") and not f.startswith("._")
]
log_path = os.path.join(SAVE_DIR, "center_slice_log.csv")

records = []
for pid in tqdm(all_pids, desc="ğŸ”„ Caching 20 CENTER slices (RGB + norm)"):
    result = process_patient(pid)
    if result:
        records.append(result)

# -----------------------------
# ê²°ê³¼ ì €ì¥
# -----------------------------
df = pd.DataFrame(records, columns=["PatientID", "ValidSlices"])
df.to_csv(log_path, index=False)
print(f"âœ… ì´ {len(df)}ëª… ìºì‹± ì™„ë£Œ (ì¤‘ì•™ 20ì¥, 3ì±„ë„, ImageNet ì •ê·œí™”), ë¡œê·¸ ì €ì¥ë¨: {log_path}")
