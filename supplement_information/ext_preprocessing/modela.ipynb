{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6de6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n",
      "CACHE_DIR: ./slice_cache0_224\n",
      "MODELS_DIR: ./models\n",
      "OUTPUT_DIR: ./features/test1_1\n",
      "[DEBUG] ëŒ€ìƒ í™˜ì ìˆ˜: 55\n",
      "0    TCGA-VS-A8EB_0000\n",
      "1    TCGA-VS-A8EC_0000\n",
      "2    TCGA-VS-A8EG_0000\n",
      "3    TCGA-VS-A8EH_0000\n",
      "4    TCGA-VS-A8EI_0000\n",
      "Name: PatientID, dtype: object\n",
      "\n",
      "========== Run 0 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/5g0wf16x3l1_ngkxjnjcsw3w0000gn/T/ipykernel_12970/3098639267.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run0:   0%|          | 0/55 [00:00<?, ?it/s]/var/folders/z1/5g0wf16x3l1_ngkxjnjcsw3w0000gn/T/ipykernel_12970/3098639267.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  imgs = torch.load(cache_path, map_location=DEVICE)  # (N, C, 224, 224)\n",
      "Extracting run0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_1.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 1 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_2.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 2 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_3.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 3 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:10<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_4.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 4 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_5.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 5 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:10<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_6.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 6 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:10<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_7.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 7 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_8.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 8 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_9.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 9 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_10.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 10 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_11.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 11 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_12.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 12 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:10<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_13.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 13 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_14.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 14 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:10<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_15.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 15 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_16.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 16 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_17.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 17 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_18.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 18 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_19.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 19 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_20.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 20 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_21.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 21 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run21.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_22.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 22 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run22.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_23.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 23 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run23.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_24.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 24 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run24.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_25.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 25 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:11<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_26.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 26 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run26.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_27.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 27 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run27.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_28.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 28 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run28.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:12<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_29.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "========== Run 29 ==========\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: best_model_beit_run29.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting run29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [01:13<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ ./features/test1_1/beit_base_patch16_224_features_30.csv\n",
      "ğŸ“Š í™˜ì ìˆ˜: 55, feature_dim: 768\n",
      "\n",
      "âœ… ëª¨ë“  ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 0. íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš” ì‹œ)\n",
    "# ================================\n",
    "# !pip install timm tqdm pandas torch\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================================\n",
    "# 1. ê²½ë¡œ ë° í™˜ê²½ ì„¤ì •\n",
    "# ================================\n",
    "CACHE_DIR   = \"./slice_cache0_224\"            # ìºì‹œëœ í™˜ìë³„ ìŠ¬ë¼ì´ìŠ¤ í…ì„œ(.pt)\n",
    "CSV_PATH    = \"./clinical.csv\"                # ì„ìƒ CSV (PatientID í¬í•¨)\n",
    "MODELS_DIR  = \"./models\"                      # ëª¨ë¸ë“¤ì´ ìˆëŠ” í´ë”\n",
    "OUTPUT_DIR  = \"./features/test1_1\"                    # ê²°ê³¼ ì €ì¥ í´ë”\n",
    "N_RUNS      = 30                              # run 0 ~ 29\n",
    "BATCH_SIZE  = 16                              # CPUì—ì„œ 8~32 ê¶Œì¥\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")                  # âœ… CPU ê°•ì œ\n",
    "torch.set_num_threads(max(1, os.cpu_count() // 2))  # ë…¸íŠ¸ë¶ CPU ê³¼ë¶€í•˜ ë°©ì§€\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"CACHE_DIR:\", CACHE_DIR)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "\n",
    "# ================================\n",
    "# 2. ëª¨ë¸ ì •ì˜ (BEiT ë°±ë³¸)\n",
    "# ================================\n",
    "class BEiTBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            \"beit_base_patch16_224\", pretrained=False, num_classes=0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)  # (B, D)\n",
    "\n",
    "# ================================\n",
    "# 3. DataFrame ë¡œë”© & PatientID ì •ë¦¬\n",
    "# ================================\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"ì„ìƒ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CSV_PATH}\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# âœ… PatientIDì— _0000 ë¶™ì—¬ì„œ ìºì‹œ íŒŒì¼ê³¼ ë§¤ì¹­\n",
    "df[\"PatientID\"] = df[\"PatientID\"].astype(str) + \"_0000\"\n",
    "\n",
    "# ìºì‹œ(.pt) íŒŒì¼ ì¡´ì¬í•˜ëŠ” í™˜ìë§Œ ë‚¨ê¸°ê¸°\n",
    "df = df[df[\"PatientID\"].apply(lambda x: os.path.exists(os.path.join(CACHE_DIR, f\"{x}.pt\")))]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"[DEBUG] ëŒ€ìƒ í™˜ì ìˆ˜: {len(df)}\")\n",
    "if len(df) == 0:\n",
    "    raise RuntimeError(\"dfê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤. CSV ë˜ëŠ” ìºì‹œ(.pt) ê²½ë¡œ í™•ì¸ í•„ìš”\")\n",
    "\n",
    "print(df[\"PatientID\"].head())\n",
    "\n",
    "# ================================\n",
    "# 4. ì—¬ëŸ¬ ëª¨ë¸ ë°˜ë³µ ì‹¤í–‰ (run 0 ~ 29)\n",
    "# ================================\n",
    "for run in range(N_RUNS):\n",
    "    print(f\"\\n========== Run {run} ==========\")\n",
    "    model_path = os.path.join(MODELS_DIR, f\"best_model_beit_run{run}.pt\")\n",
    "    out_csv    = os.path.join(OUTPUT_DIR, f\"beit_base_patch16_224_features_{run+1}.csv\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€ â†’ {model_path}\")\n",
    "        continue\n",
    "\n",
    "    # ----- 4-1) ëª¨ë¸ ë¡œë”© -----\n",
    "    model = BEiTBackbone().to(DEVICE)\n",
    "    ckpt = torch.load(model_path, map_location=DEVICE)\n",
    "\n",
    "    # ckpt í˜•íƒœì— ë”°ë¼ state_dict ì¶”ì¶œ\n",
    "    state_dict = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
    "\n",
    "    # 'backbone.' prefix ì •ë¦¬ ë° í˜¸í™˜ í‚¤ë§Œ ë¡œë”©\n",
    "    filtered = {\n",
    "        k.replace(\"backbone.\", \"\"): v\n",
    "        for k, v in state_dict.items()\n",
    "        if k.startswith(\"backbone.\") or k in model.backbone.state_dict()\n",
    "    }\n",
    "\n",
    "    missing, unexpected = model.backbone.load_state_dict(filtered, strict=False)\n",
    "    if missing:\n",
    "        print(\"âš ï¸ missing keys (ì¼ë¶€ë§Œ í‘œì‹œ):\", missing[:5], \"...\" if len(missing) > 5 else \"\")\n",
    "    if unexpected:\n",
    "        print(\"âš ï¸ unexpected keys (ì¼ë¶€ë§Œ í‘œì‹œ):\", unexpected[:5], \"...\" if len(unexpected) > 5 else \"\")\n",
    "\n",
    "    model.eval()\n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ:\", os.path.basename(model_path))\n",
    "\n",
    "    # ----- 4-2) Feature ì¶”ì¶œ -----\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Extracting run{run}\"):\n",
    "            pid = row[\"PatientID\"]\n",
    "            cache_path = os.path.join(CACHE_DIR, f\"{pid}.pt\")\n",
    "            if not os.path.exists(cache_path):\n",
    "                print(f\"âš ï¸ {pid} ìºì‹œ ì—†ìŒ â†’ skip\")\n",
    "                continue\n",
    "\n",
    "            imgs = torch.load(cache_path, map_location=DEVICE)  # (N, C, 224, 224)\n",
    "            imgs = imgs.float()\n",
    "\n",
    "            # ë‹¨ì¼ ì±„ë„ì´ë©´ 3ì±„ë„ë¡œ í™•ì¥\n",
    "            if imgs.ndim == 4 and imgs.shape[1] == 1:\n",
    "                imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "            outs = []\n",
    "            for start in range(0, imgs.shape[0], BATCH_SIZE):\n",
    "                batch = imgs[start:start + BATCH_SIZE].to(DEVICE)\n",
    "                out = model(batch)  # (b, D)\n",
    "                outs.append(out.cpu())\n",
    "\n",
    "            feats = torch.cat(outs, dim=0)       # (N, D)\n",
    "            mean_feat = feats.mean(dim=0).numpy().tolist()\n",
    "            features.append([pid] + mean_feat)\n",
    "\n",
    "    if not features:\n",
    "        print(f\"âš ï¸ ì¶”ì¶œëœ featureê°€ ì—†ì–´ ì €ì¥ì„ ìƒëµí•©ë‹ˆë‹¤ (run {run}).\")\n",
    "        continue\n",
    "\n",
    "    # ----- 4-3) ì €ì¥ -----\n",
    "    feature_dim = len(features[0]) - 1\n",
    "    columns = [\"PatientID\"] + [f\"feat_{i}\" for i in range(feature_dim)]\n",
    "    df_feat = pd.DataFrame(features, columns=columns)\n",
    "    df_feat.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"ğŸ‰ ì €ì¥ ì™„ë£Œ â†’ {out_csv}\")\n",
    "    print(f\"ğŸ“Š í™˜ì ìˆ˜: {df_feat.shape[0]}, feature_dim: {feature_dim}\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
